{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/eftekhar-hossain/Disaster_IEEE-Access/blob/main/damage_identification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D09VDHN9xiww"
   },
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6OdpHrd7yReb",
    "outputId": "88a14810-6501-4a40-d14b-adfc8101ff57"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.97 s, sys: 1.24 s, total: 8.21 s\n",
      "Wall time: 13.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import re,nltk,json\n",
    "from sklearn.metrics import confusion_matrix,classification_report \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,roc_auc_score\n",
    "from sklearn.metrics import average_precision_score,roc_auc_score, roc_curve, precision_recall_curve\n",
    "from keras.utils.vis_utils import plot_model\n",
    "np.random.seed(42)\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import ToktokTokenizer\n",
    "import string, spacy,unicodedata, random\n",
    "from bs4 import BeautifulSoup\n",
    "class color: # Text style\n",
    "   PURPLE = '\\033[95m'\n",
    "   CYAN = '\\033[96m'\n",
    "   DARKCYAN = '\\033[36m'\n",
    "   BLUE = '\\033[94m'\n",
    "   GREEN = '\\033[92m'\n",
    "   YELLOW = '\\033[93m'\n",
    "   RED = '\\033[91m'\n",
    "   BOLD = '\\033[1m'\n",
    "   UNDERLINE = '\\033[4m'\n",
    "   END = '\\033[0m'\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "### Pretrained Word Embeddings\n",
    "pretrained_path = \"/content/drive/MyDrive/TaheriThesis/Dataset/PreTrained Wordembedding/\"\n",
    "# dataset_path = \"/content/drive/MyDrive/Colab Notebooks/MSC Presentation Tasks/Disaster Response/Images/\"\n",
    "# folder_path = \"/content/drive/MyDrive/Colab Notebooks/MSC Presentation Tasks/Disaster Response/\"\n",
    "models_path = \"/content/drive/MyDrive/TaheriThesis/Dataset/Multimodal Sentiment/\"\n",
    "\n",
    "\n",
    "folder_path = \"/content/drive/MyDrive/TaheriThesis/Dataset/\"\n",
    "# models_path = \"/content/drive/MyDrive/TaheriThesis/Dataset/Multimodal Sentiment/Models/\"\n",
    "# results_path = \"/content/drive/MyDrive/TaheriThesis/Dataset/Multimodal Sentiment/Results/\"\n",
    "dataset_path = \"/content/drive/MyDrive/TaheriThesis/Dataset/Images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "l767bYFbGNLf"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Embedding, LSTM, multiply\n",
    "from keras.models import Model\n",
    "from keras import preprocessing, Input\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "#Import from keras_preprocessing not from keras.preprocessing\n",
    "# from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import regularizers, optimizers\n",
    "from tensorflow.keras.models import load_model\n",
    "import itertools\n",
    "from PIL import Image, ImageFile\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Concatenate, Dense, Input, LSTM, Embedding, Dropout, Activation, GRU, Flatten\n",
    "from tensorflow.keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Convolution1D,MaxPooling1D,Conv1D\n",
    "from tensorflow.keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from tensorflow.keras.layers import Add, BatchNormalization, Activation, Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop,Adam,SGD,Nadam\n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jjImoyXizNSk"
   },
   "source": [
    "#Fetching Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "nt9hWjXNzQxq"
   },
   "outputs": [],
   "source": [
    "# train_data = pd.read_excel(folder_path+'train.xlsx')\n",
    "# test_data = pd.read_csv(folder_path+'test.xlsx')\n",
    "# valid_data = pd.read_excel(main_path+'valid_new.xlsx')\n",
    "train_data = pd.read_csv(folder_path+'train.csv')\n",
    "valid_data = pd.read_csv(folder_path+'val.csv')\n",
    "test_data = pd.read_csv(folder_path+'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1lDAsGYgMs8r",
    "outputId": "016ee659-a7d6-414d-a509-13cafb2bafa3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['image_name', 'Captions', 'Label_Sentiment', 'Label'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RhUgGvUa2WFX",
    "outputId": "b0c0a99b-508b-4976-e3ff-dc6e8e10fcdd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    861\n",
       "6    716\n",
       "4    623\n",
       "1    477\n",
       "5    408\n",
       "3    400\n",
       "2    348\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nPO59gZr2c5p",
    "outputId": "d9529aca-ab1f-489f-b554-8c7cb07120b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    93\n",
       "6    79\n",
       "4    68\n",
       "5    46\n",
       "3    44\n",
       "1    44\n",
       "2    40\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "qJO4yFDY2nTP"
   },
   "outputs": [],
   "source": [
    "# train_data['enc_label'] = train_data['label'].replace({'non_damage':0,'damaged_infrastructure':1,'damaged_nature':2,\n",
    "#                                                        'fires':3,'flood':4,'human_damage':5 })\n",
    "# test_data['enc_label'] = test_data['label'].replace({'non_damage':0,'damaged_infrastructure':1,'damaged_nature':2,\n",
    "#                                                      'fires':3,'flood':4,'human_damage':5 })\n",
    "\n",
    "\n",
    "train_data['enc_label'] = train_data['Label_Sentiment'].replace({'happy':0,'angry':1,'disgust':2,'fear':3,'sad':4,'surprise':5,'other':6})\n",
    "valid_data['enc_label'] = valid_data['Label_Sentiment'].replace({'happy':0,'angry':1,'disgust':2,'fear':3,'sad':4,'surprise':5,'other':6})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "TKtfQsnn_aSt"
   },
   "outputs": [],
   "source": [
    "test_data['enc_label'] = test_data['Label_Sentiment'].replace({'happy':0,'angry':1,'disgust':2,'fear':3,'sad':4,'surprise':5,'other':6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NqXJL1QY3Gte",
    "outputId": "d1a3fa5b-e3bd-47f3-9689-803ab984201d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the training data ==>  (3833, 5)\n",
      "Size of the training data ==>  (414, 5)\n",
      "Size of the Test data ==> (414, 5)\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of the training data ==> \", train_data.shape)\n",
    "print(\"Size of the training data ==> \", valid_data.shape)\n",
    "print(\"Size of the Test data ==>\", test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-f7tj6t_MbR2"
   },
   "source": [
    "## Image Fetching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "ER4zNOmfMe_8"
   },
   "outputs": [],
   "source": [
    "## collect image names from the folders\n",
    "def create_img_array(img_dirct):\n",
    "    all_imgs = []\n",
    "    for root, j, files in os.walk(img_dirct):\n",
    "        for file in files:\n",
    "            file = root + '' + file\n",
    "            all_imgs.append(file)\n",
    "    return all_imgs\n",
    "\n",
    "def create_img_path(DF, Col_name, img_dir):\n",
    "    img_path = [img_dir + '' + name for name in DF[Col_name]]\n",
    "    return img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1X--YjxFMo4v"
   },
   "outputs": [],
   "source": [
    "# Creating train, test and validation image path\n",
    "train_img_path = create_img_path(train_data,'image_name', dataset_path)\n",
    "valid_img_path = create_img_path(valid_data,'image_name', dataset_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "LI_xecOf_UD4"
   },
   "outputs": [],
   "source": [
    "test_img_path = create_img_path(test_data,'image_name', dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "t3FUNU_bM7Tn"
   },
   "outputs": [],
   "source": [
    "# Function that returns image reading from the path\n",
    "def get_input(path):\n",
    "    # Loading image from given path\n",
    "    # and resizing it to 150*150*3 format\n",
    "    ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "    img= tf.keras.utils.load_img(path, target_size=(150,150)) \n",
    "    # img.close()   \n",
    "    return(img)\n",
    "\n",
    "# Takes in image and preprocess it\n",
    "def process_input(img):\n",
    "    # Converting image to array    \n",
    "    img_data =tf.keras.utils.img_to_array(img)\n",
    "    # Adding one more dimension to array    \n",
    "    img_data = np.expand_dims(img_data, axis=0)\n",
    "    #     \n",
    "    img_data = preprocess_input(img_data)\n",
    "    #img_data = preprocess_input(img_data)\n",
    "    return(img_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pUdvKi_yNCb5"
   },
   "outputs": [],
   "source": [
    "# Create an array of training images\n",
    "train_images = []\n",
    "for n,i in enumerate(train_img_path):\n",
    "  input_img = get_input(i)\n",
    "  process_img = process_input(input_img)\n",
    "  # print(n)\n",
    "  train_images.append(process_img[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WPLJrKoAMXxE"
   },
   "outputs": [],
   "source": [
    "# Create an array of training images\n",
    "valid_images = []\n",
    "for n,i in enumerate(valid_img_path):\n",
    "  input_img = get_input(i)\n",
    "  process_img = process_input(input_img)\n",
    "  # print(n)\n",
    "  valid_images.append(process_img[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "KeGcMyaKY7s_"
   },
   "outputs": [],
   "source": [
    "# Create an array of training images\n",
    "test_images = []\n",
    "for n,i in enumerate(test_img_path):\n",
    "  input_img = get_input(i)\n",
    "  process_img = process_input(input_img)\n",
    "  # print(n)\n",
    "  test_images.append(process_img[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PTGSeCyIb3i0"
   },
   "outputs": [],
   "source": [
    "# convert into numpy array\n",
    "train_image = np.array(train_images)\n",
    "# convert into numpy array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fjUW4W8RMdS3"
   },
   "outputs": [],
   "source": [
    "valid_image = np.array(valid_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "R6dx_Cjb_lCv"
   },
   "outputs": [],
   "source": [
    "test_image = np.array(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cT1sl0lZx_KG"
   },
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "with open(dataset_path+'train.pkl','wb') as f:\n",
    "    pkl.dump(train_image, f)\n",
    "\n",
    "# with open(dataset_path+'test.pkl','wb') as f:\n",
    "#     pkl.dump(test_image, f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hVimkLOoMjW0"
   },
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "with open(dataset_path+'valid.pkl','wb') as f:\n",
    "    pkl.dump(valid_image, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "wk1ZnD8YAwIF"
   },
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "\n",
    "with open(dataset_path+'test.pkl','wb') as f:\n",
    "    pkl.dump(test_image, f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AKDZjc1uxvvh",
    "outputId": "54db5008-dc5c-4da5-ff93-22247de4bfc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Images:--  (3833, 150, 150, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "with open(dataset_path+'train.pkl','rb') as f:\n",
    "  train_image = pkl.load(f)\n",
    "  print(\"Training Images:-- \",train_image.shape)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AlUS5zduMnG1",
    "outputId": "58b8785e-50fe-44eb-d88c-b790c6571485"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Images:--  (414, 150, 150, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open(dataset_path+'valid.pkl','rb') as f:\n",
    "  valid_image = pkl.load(f)\n",
    "  print(\"Validation Images:-- \",valid_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6kG8SrK5A1Dm",
    "outputId": "aceecc64-4c70-4c23-b691-fb3c26c784ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Images:--  (414, 150, 150, 3)\n"
     ]
    }
   ],
   "source": [
    "with open(dataset_path+'test.pkl','rb') as f:\n",
    "  test_image = pkl.load(f)\n",
    "  print(\"Test Images:-- \",test_image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C55eRoK23rzC"
   },
   "source": [
    "## One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dNGZabRk3vSN"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vfd2Z0c-3x6_"
   },
   "outputs": [],
   "source": [
    "# encoder=OneHotEncoder(sparse=False)\n",
    "\n",
    "# encoded_labels = pd.DataFrame (encoder.fit_transform(train_data[['label']]))\n",
    "\n",
    "# encoded_labels .columns = encoder.get_feature_names(['label'])\n",
    "\n",
    "# train_data= pd.concat([train_data, encoded_labels ], axis=1)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Define the list of categories for your Label_Sentiment variable\n",
    "categories = ['happy', 'angry', 'disgust', 'fear', 'sad', 'surprise', 'other']\n",
    "\n",
    "# Perform one-hot encoding using get_dummies() function\n",
    "encoded_labels = pd.get_dummies(train_data['Label_Sentiment'], columns=categories, prefix='Label_Sentiment')\n",
    "\n",
    "# Concatenate the encoded labels with your original train_data DataFrame\n",
    "train_data = pd.concat([train_data, encoded_labels], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OmdmEo9033SX",
    "outputId": "70ad29c1-9fc8-42d1-d4f8-e463cc739d00"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['image_name', 'Captions', 'Label_Sentiment', 'Label', 'enc_label',\n",
       "       'Label_Sentiment_angry', 'Label_Sentiment_disgust',\n",
       "       'Label_Sentiment_fear', 'Label_Sentiment_happy',\n",
       "       'Label_Sentiment_other', 'Label_Sentiment_sad',\n",
       "       'Label_Sentiment_surprise'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "alEhfx5H3-tX",
    "outputId": "01c9ebe6-a04e-468c-fb1b-a1ca1a348b17"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-a7d2f8e7-9e75-44ac-aee6-d835c99a1f7d\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>Captions</th>\n",
       "      <th>Label_Sentiment</th>\n",
       "      <th>Label</th>\n",
       "      <th>enc_label</th>\n",
       "      <th>angry</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>happy</th>\n",
       "      <th>other</th>\n",
       "      <th>sad</th>\n",
       "      <th>surprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>205.jpg</td>\n",
       "      <td>নির্বোধ দেখার এবং আপনি যে যত্নশীল তা না করার ক...</td>\n",
       "      <td>other</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>209.jpg</td>\n",
       "      <td>একটি বোর্ডার আর্ম স্কেটার একটি আমন্ত্রণ উপার্জ...</td>\n",
       "      <td>other</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>210.jpg</td>\n",
       "      <td>যদি শরীর দুর্বল হয় তবে মন শক্তিশালী হবে না।</td>\n",
       "      <td>other</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>215.jpg</td>\n",
       "      <td>একজন ধার্মিক ব্যক্তির কার্যকর উত্সাহ প্রার্থনা...</td>\n",
       "      <td>other</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>222.jpg</td>\n",
       "      <td>অসমাপ্ত ?</td>\n",
       "      <td>other</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3828</th>\n",
       "      <td>4676.jpg</td>\n",
       "      <td>অভিনন্দন ২ প্রথম আইবিএম প্যাথওয়েসটেক পণ্ডিতরা...</td>\n",
       "      <td>happy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3829</th>\n",
       "      <td>4677.jpg</td>\n",
       "      <td>সবেমাত্র আমার চুলের সাথে রুটোশায়ার স্ক্যাল্প ...</td>\n",
       "      <td>happy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3830</th>\n",
       "      <td>4678.jpg</td>\n",
       "      <td>সবেমাত্র এই ওক ড্রেসারটি শেষ করেছেন।</td>\n",
       "      <td>happy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3831</th>\n",
       "      <td>4682.jpg</td>\n",
       "      <td>সুগারম্যান রজার্স মামলা-মোকদ্দমা কেমব্রিজে গত ...</td>\n",
       "      <td>happy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3832</th>\n",
       "      <td>4704.jpg</td>\n",
       "      <td>সন্ত্রাসীদের আতঙ্কিত করা উচিত। কী সেই নাজি প্র...</td>\n",
       "      <td>happy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3833 rows × 12 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a7d2f8e7-9e75-44ac-aee6-d835c99a1f7d')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-a7d2f8e7-9e75-44ac-aee6-d835c99a1f7d button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-a7d2f8e7-9e75-44ac-aee6-d835c99a1f7d');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "     image_name                                           Captions  \\\n",
       "0       205.jpg  নির্বোধ দেখার এবং আপনি যে যত্নশীল তা না করার ক...   \n",
       "1       209.jpg  একটি বোর্ডার আর্ম স্কেটার একটি আমন্ত্রণ উপার্জ...   \n",
       "2       210.jpg       যদি শরীর দুর্বল হয় তবে মন শক্তিশালী হবে না।   \n",
       "3       215.jpg  একজন ধার্মিক ব্যক্তির কার্যকর উত্সাহ প্রার্থনা...   \n",
       "4       222.jpg                                          অসমাপ্ত ?   \n",
       "...         ...                                                ...   \n",
       "3828   4676.jpg  অভিনন্দন ২ প্রথম আইবিএম প্যাথওয়েসটেক পণ্ডিতরা...   \n",
       "3829   4677.jpg  সবেমাত্র আমার চুলের সাথে রুটোশায়ার স্ক্যাল্প ...   \n",
       "3830   4678.jpg               সবেমাত্র এই ওক ড্রেসারটি শেষ করেছেন।   \n",
       "3831   4682.jpg  সুগারম্যান রজার্স মামলা-মোকদ্দমা কেমব্রিজে গত ...   \n",
       "3832   4704.jpg  সন্ত্রাসীদের আতঙ্কিত করা উচিত। কী সেই নাজি প্র...   \n",
       "\n",
       "     Label_Sentiment  Label  enc_label  angry  disgust  fear  happy  other  \\\n",
       "0              other      6          6      0        0     0      0      1   \n",
       "1              other      6          6      0        0     0      0      1   \n",
       "2              other      6          6      0        0     0      0      1   \n",
       "3              other      6          6      0        0     0      0      1   \n",
       "4              other      6          6      0        0     0      0      1   \n",
       "...              ...    ...        ...    ...      ...   ...    ...    ...   \n",
       "3828           happy      0          0      0        0     0      1      0   \n",
       "3829           happy      0          0      0        0     0      1      0   \n",
       "3830           happy      0          0      0        0     0      1      0   \n",
       "3831           happy      0          0      0        0     0      1      0   \n",
       "3832           happy      0          0      0        0     0      1      0   \n",
       "\n",
       "      sad  surprise  \n",
       "0       0         0  \n",
       "1       0         0  \n",
       "2       0         0  \n",
       "3       0         0  \n",
       "4       0         0  \n",
       "...   ...       ...  \n",
       "3828    0         0  \n",
       "3829    0         0  \n",
       "3830    0         0  \n",
       "3831    0         0  \n",
       "3832    0         0  \n",
       "\n",
       "[3833 rows x 12 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_data = train_data.rename(columns={'label_damaged_infrastructure':'damaged_infrastructure', 'label_damaged_nature':'damaged_nature', \n",
    "#                                         'label_fires':'fires','label_flood':'flood',\n",
    "#                                         'label_human_damage':'human_damage', 'label_non_damage':'non_damage'})\n",
    "\n",
    "\n",
    "train_data = train_data.rename(columns={'Label_Sentiment_happy':'happy', \n",
    "                                        'Label_Sentiment_angry':'angry',\n",
    "                                        'Label_Sentiment_disgust':'disgust',\n",
    "                                        'Label_Sentiment_fear':'fear',\n",
    "                                        'Label_Sentiment_sad':'sad',\n",
    "                                        'Label_Sentiment_surprise':'surprise',\n",
    "                                        'Label_Sentiment_other':'other'})\n",
    "     \n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6-XCXOsb-zxc",
    "outputId": "07c1bfbf-7e46-4b2e-d690-ae610a1e7bc0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['image_name', 'Captions', 'Label_Sentiment', 'Label', 'enc_label',\n",
       "       'angry', 'disgust', 'fear', 'happy', 'other', 'sad', 'surprise'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "48JRGZ4U6Kvv"
   },
   "outputs": [],
   "source": [
    "train_data.Captions = train_data.Captions.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gyyw4VqlFXS_"
   },
   "source": [
    "##Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "1rgUkMnlFbBU"
   },
   "outputs": [],
   "source": [
    "'''Evaluation Parameters'''\n",
    "\n",
    "def print_metrices(true,pred):\n",
    "    print(confusion_matrix(true,pred))\n",
    "    print(classification_report(true,pred))\n",
    "    print(\"Accuracy : \",accuracy_score(true,pred))\n",
    "    print(\"Precison : \",precision_score(true,pred, average = 'weighted'))\n",
    "    print(\"Recall : \",recall_score(true,pred,  average = 'weighted'))\n",
    "    print(\"F1 : \",f1_score(true,pred,  average = 'weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i27YJBb9V_jk"
   },
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "PwSSTl3kWB5T"
   },
   "outputs": [],
   "source": [
    "## Confusion matrix function\n",
    "def con_mat(true,pred,class_names,model_name):\n",
    "  cm = confusion_matrix(true,pred)\n",
    "  #sns.set()\n",
    "  plt.figure(figsize =(4, 3))\n",
    "  ax = plt.subplot()\n",
    " # 'Greys', 'Purples', 'Blues', 'Greens', 'Oranges', 'Reds','YlOrBr', 'YlOrRd', 'OrRd', 'PuRd', 'RdPu', 'BuPu',\n",
    "            #'GnBu', 'PuBu', 'YlGnBu', 'PuBuGn', 'BuGn', 'YlGn'\n",
    "  sns.heatmap(cm, annot=True,fmt=\"d\",cmap='YlOrRd', ax = ax,annot_kws={\"size\": 10},) #annot=True to annotate cells\n",
    "  # labels, title and ticks\n",
    "  ax.set_xlabel('Predicted labels',fontsize=10)\n",
    "  ax.set_ylabel('True labels',fontsize=10) \n",
    "  #ax.set_title(f'Confusion Matrix of {model_name}',fontsize=10) \n",
    "  ax.xaxis.set_ticklabels(class_names, rotation=45); ax.yaxis.set_ticklabels(class_names, rotation=45);\n",
    "  ax.xaxis.tick_top()\n",
    " # plt.savefig(folder_path + f\"{model_name}.png\",bbox_inches='tight',dpi =500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L9omUBz0z9Iq",
    "outputId": "dbbf53b7-b54a-42de-dd98-a71fa0d4c63c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.6359714617554338,\n",
       " 1: 1.147948487571129,\n",
       " 2: 1.5734811165845648,\n",
       " 3: 1.3689285714285715,\n",
       " 4: 0.881757533931447,\n",
       " 5: 1.3355400696864113,\n",
       " 6: 0.7647645650438947}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import compute_class_weight\n",
    "class_weights = compute_class_weight(\n",
    "                                        class_weight = \"balanced\",\n",
    "                                        classes = np.unique(train_data['enc_label']),\n",
    "                                        y = train_data['enc_label']                                                   \n",
    "                                    )\n",
    "class_weights = dict(zip(np.unique(train_data['enc_label']), class_weights))\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pDf4t5nANV1N"
   },
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3UdewIycNmIf"
   },
   "outputs": [],
   "source": [
    "''' Callbacks'''\n",
    "keras.backend.clear_session()\n",
    "def callbacks_check(model_name):\n",
    "  num_classes = 7\n",
    "  accuracy_threshold = 0.99\n",
    "\n",
    "  class myCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('accuracy')>accuracy_threshold):\n",
    "          print(\"\\nReached %2.2f%% accuracy so we will stop trianing\" % (accuracy_threshold*100))\n",
    "          self.model.stop_training = True\n",
    "\n",
    "  acc_callback = myCallback()\n",
    "  # Saved the Best Model\n",
    "  filepath = models_path+'Models_2/'+f\"{model_name}.h5\"\n",
    "  checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=2, save_best_only=True, \n",
    "                                             save_weights_only=False, mode='max')\n",
    "  # callback list\n",
    "  callback_list = [acc_callback, checkpoint] \n",
    "\n",
    "  return callback_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yzaDrX3dlrjH"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train=to_categorical(train_data['enc_label'])\n",
    "y_valid=to_categorical(valid_data['enc_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TMCC_pqPBAMr"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y_test=to_categorical(test_data['enc_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VxoNP4ytlwJg",
    "outputId": "5b13a720-446c-4624-a668-c89584b49f9f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fE_uBG0a_Vej"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JSLsF0v4cZ7d"
   },
   "source": [
    "#Visual Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gsRonbngccEl"
   },
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "def visual_models():\n",
    "\n",
    "\n",
    "  #### Resnet\n",
    "  resnet = ResNet50(weights='imagenet', include_top=False,input_shape=(150, 150, 3))\n",
    "  #resnet.trainable = False\n",
    "  for layer in resnet.layers[0:-10]:\n",
    "      layer.trainable = False\n",
    "  # add a global spatial average pooling layer\n",
    "  y = resnet.output\n",
    "  pool1 = GlobalAveragePooling2D()(y)\n",
    "  # let's add a fully-connected layer\n",
    "  #flat1 = Flatten()(pool1)\n",
    "  # and a logistic layer -- let's say we have 200 classes\n",
    "  #hidden = Dense(512, activation='relu')(flat1)\n",
    "  #dropout1 = Dropout(0.1)(hidden)\n",
    "  output1 = Dense(7, activation='softmax')(pool1)\n",
    "  # this is the model we will train\n",
    "  resnet_img_model = Model(inputs=resnet.input, outputs=output1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  models = [resnet_img_model]\n",
    "\n",
    "  return models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EJv91NwYMse0",
    "outputId": "d43088cf-d762-4625-be27-2a90dfdae316"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 3s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94765736/94765736 [==============================] - 4s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87910968/87910968 [==============================] - 4s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "29084464/29084464 [==============================] - 2s 0us/step\n",
      "Model Name: vgg16\n",
      "\n",
      "Epoch 1/30\n",
      "  6/120 [>.............................] - ETA: 22s - loss: 27.7359 - accuracy: 0.1875"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0648s vs `on_train_batch_end` time: 0.1065s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - ETA: 0s - loss: 3.2496 - accuracy: 0.2095\n",
      "Epoch 1: val_accuracy improved from -inf to 0.26329, saving model to /content/drive/MyDrive/TaheriThesis/Dataset/Multimodal Sentiment/Models_2/vgg16.h5\n",
      "120/120 [==============================] - 61s 323ms/step - loss: 3.2496 - accuracy: 0.2095 - val_loss: 1.9123 - val_accuracy: 0.2633\n",
      "Epoch 2/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.9056 - accuracy: 0.2158\n",
      "Epoch 2: val_accuracy did not improve from 0.26329\n",
      "120/120 [==============================] - 24s 201ms/step - loss: 1.9056 - accuracy: 0.2158 - val_loss: 1.9078 - val_accuracy: 0.2222\n",
      "Epoch 3/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.9013 - accuracy: 0.2220\n",
      "Epoch 3: val_accuracy did not improve from 0.26329\n",
      "120/120 [==============================] - 25s 207ms/step - loss: 1.9013 - accuracy: 0.2220 - val_loss: 1.9031 - val_accuracy: 0.2222\n",
      "Epoch 4/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.9557 - accuracy: 0.2137\n",
      "Epoch 4: val_accuracy did not improve from 0.26329\n",
      "120/120 [==============================] - 25s 208ms/step - loss: 1.9557 - accuracy: 0.2137 - val_loss: 2.3865 - val_accuracy: 0.1063\n",
      "Epoch 5/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.9088 - accuracy: 0.2244\n",
      "Epoch 5: val_accuracy did not improve from 0.26329\n",
      "120/120 [==============================] - 24s 202ms/step - loss: 1.9088 - accuracy: 0.2244 - val_loss: 1.9148 - val_accuracy: 0.2198\n",
      "Epoch 6/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.8977 - accuracy: 0.2246\n",
      "Epoch 6: val_accuracy did not improve from 0.26329\n",
      "120/120 [==============================] - 25s 207ms/step - loss: 1.8977 - accuracy: 0.2246 - val_loss: 1.9145 - val_accuracy: 0.2198\n",
      "Epoch 7/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.8970 - accuracy: 0.2246\n",
      "Epoch 7: val_accuracy did not improve from 0.26329\n",
      "120/120 [==============================] - 25s 204ms/step - loss: 1.8970 - accuracy: 0.2246 - val_loss: 1.9144 - val_accuracy: 0.2198\n",
      "Epoch 8/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.8974 - accuracy: 0.2246\n",
      "Epoch 8: val_accuracy did not improve from 0.26329\n",
      "120/120 [==============================] - 25s 208ms/step - loss: 1.8974 - accuracy: 0.2246 - val_loss: 1.9148 - val_accuracy: 0.2198\n",
      "Epoch 9/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.8972 - accuracy: 0.2246\n",
      "Epoch 9: val_accuracy did not improve from 0.26329\n",
      "120/120 [==============================] - 25s 209ms/step - loss: 1.8972 - accuracy: 0.2246 - val_loss: 1.9147 - val_accuracy: 0.2198\n",
      "Epoch 10/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.8969 - accuracy: 0.2246\n",
      "Epoch 10: val_accuracy did not improve from 0.26329\n",
      "120/120 [==============================] - 25s 209ms/step - loss: 1.8969 - accuracy: 0.2246 - val_loss: 1.9155 - val_accuracy: 0.2198\n",
      "Epoch 11/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.8969 - accuracy: 0.2246\n",
      "Epoch 11: val_accuracy did not improve from 0.26329\n",
      "120/120 [==============================] - 25s 206ms/step - loss: 1.8969 - accuracy: 0.2246 - val_loss: 1.9154 - val_accuracy: 0.2198\n",
      "Epoch 12/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.8967 - accuracy: 0.2246\n",
      "Epoch 12: val_accuracy did not improve from 0.26329\n",
      "120/120 [==============================] - 25s 206ms/step - loss: 1.8967 - accuracy: 0.2246 - val_loss: 1.9148 - val_accuracy: 0.2198\n",
      "Epoch 13/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.8975 - accuracy: 0.2246\n",
      "Epoch 13: val_accuracy did not improve from 0.26329\n",
      "120/120 [==============================] - 25s 210ms/step - loss: 1.8975 - accuracy: 0.2246 - val_loss: 1.9140 - val_accuracy: 0.2198\n",
      "Epoch 14/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.8972 - accuracy: 0.2246\n",
      "Epoch 14: val_accuracy did not improve from 0.26329\n",
      "120/120 [==============================] - 25s 210ms/step - loss: 1.8972 - accuracy: 0.2246 - val_loss: 1.9142 - val_accuracy: 0.2198\n",
      "Epoch 15/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.8970 - accuracy: 0.2246\n",
      "Epoch 15: val_accuracy did not improve from 0.26329\n",
      "120/120 [==============================] - 25s 211ms/step - loss: 1.8970 - accuracy: 0.2246 - val_loss: 1.9148 - val_accuracy: 0.2198\n",
      "Epoch 16/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.8969 - accuracy: 0.2246\n",
      "Epoch 16: val_accuracy did not improve from 0.26329\n",
      "120/120 [==============================] - 25s 211ms/step - loss: 1.8969 - accuracy: 0.2246 - val_loss: 1.9146 - val_accuracy: 0.2198\n",
      "Epoch 17/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.8970 - accuracy: 0.2246\n",
      "Epoch 17: val_accuracy did not improve from 0.26329\n",
      "120/120 [==============================] - 25s 211ms/step - loss: 1.8970 - accuracy: 0.2246 - val_loss: 1.9149 - val_accuracy: 0.2198\n",
      "Epoch 18/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.8965 - accuracy: 0.2246\n",
      "Epoch 18: val_accuracy did not improve from 0.26329\n",
      "120/120 [==============================] - 25s 207ms/step - loss: 1.8965 - accuracy: 0.2246 - val_loss: 1.9150 - val_accuracy: 0.2198\n",
      "Epoch 19/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.8976 - accuracy: 0.2246\n",
      "Epoch 19: val_accuracy did not improve from 0.26329\n",
      "120/120 [==============================] - 25s 207ms/step - loss: 1.8976 - accuracy: 0.2246 - val_loss: 1.9150 - val_accuracy: 0.2198\n",
      "Epoch 20/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.8960 - accuracy: 0.2246\n",
      "Epoch 20: val_accuracy did not improve from 0.26329\n",
      "120/120 [==============================] - 25s 207ms/step - loss: 1.8960 - accuracy: 0.2246 - val_loss: 1.9151 - val_accuracy: 0.2198\n",
      "Epoch 21/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.8972 - accuracy: 0.2246\n",
      "Epoch 21: val_accuracy did not improve from 0.26329\n",
      "120/120 [==============================] - 25s 208ms/step - loss: 1.8972 - accuracy: 0.2246 - val_loss: 1.9142 - val_accuracy: 0.2198\n",
      "Epoch 22/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.8974 - accuracy: 0.2246\n",
      "Epoch 22: val_accuracy did not improve from 0.26329\n",
      "120/120 [==============================] - 25s 211ms/step - loss: 1.8974 - accuracy: 0.2246 - val_loss: 1.9146 - val_accuracy: 0.2198\n",
      "Epoch 23/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.8975 - accuracy: 0.2246\n",
      "Epoch 23: val_accuracy did not improve from 0.26329\n",
      "120/120 [==============================] - 25s 208ms/step - loss: 1.8975 - accuracy: 0.2246 - val_loss: 1.9144 - val_accuracy: 0.2198\n",
      "Epoch 24/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.8977 - accuracy: 0.2244\n",
      "Epoch 24: val_accuracy did not improve from 0.26329\n",
      "120/120 [==============================] - 25s 212ms/step - loss: 1.8977 - accuracy: 0.2244 - val_loss: 1.9146 - val_accuracy: 0.2198\n",
      "Epoch 25/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.8978 - accuracy: 0.2246\n",
      "Epoch 25: val_accuracy did not improve from 0.26329\n",
      "120/120 [==============================] - 25s 212ms/step - loss: 1.8978 - accuracy: 0.2246 - val_loss: 1.9147 - val_accuracy: 0.2198\n",
      "Epoch 26/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.8963 - accuracy: 0.2246\n",
      "Epoch 26: val_accuracy did not improve from 0.26329\n",
      "120/120 [==============================] - 25s 212ms/step - loss: 1.8963 - accuracy: 0.2246 - val_loss: 1.9141 - val_accuracy: 0.2198\n",
      "Epoch 27/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.8967 - accuracy: 0.2249\n",
      "Epoch 27: val_accuracy did not improve from 0.26329\n",
      "120/120 [==============================] - 25s 208ms/step - loss: 1.8967 - accuracy: 0.2249 - val_loss: 1.9150 - val_accuracy: 0.2198\n",
      "Epoch 28/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.8968 - accuracy: 0.2246\n",
      "Epoch 28: val_accuracy did not improve from 0.26329\n",
      "120/120 [==============================] - 25s 212ms/step - loss: 1.8968 - accuracy: 0.2246 - val_loss: 1.9150 - val_accuracy: 0.2198\n",
      "Epoch 29/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.8965 - accuracy: 0.2246\n",
      "Epoch 29: val_accuracy did not improve from 0.26329\n",
      "120/120 [==============================] - 25s 208ms/step - loss: 1.8965 - accuracy: 0.2246 - val_loss: 1.9150 - val_accuracy: 0.2198\n",
      "Epoch 30/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.8960 - accuracy: 0.2246\n",
      "Epoch 30: val_accuracy did not improve from 0.26329\n",
      "120/120 [==============================] - 25s 209ms/step - loss: 1.8960 - accuracy: 0.2246 - val_loss: 1.9152 - val_accuracy: 0.2198\n",
      "Model Name: resnet\n",
      "\n",
      "Epoch 1/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 2.0747 - accuracy: 0.2559\n",
      "Epoch 1: val_accuracy improved from -inf to 0.41546, saving model to /content/drive/MyDrive/TaheriThesis/Dataset/Multimodal Sentiment/Models_2/resnet.h5\n",
      "120/120 [==============================] - 21s 122ms/step - loss: 2.0747 - accuracy: 0.2559 - val_loss: 1.6309 - val_accuracy: 0.4155\n",
      "Epoch 2/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.4883 - accuracy: 0.4480\n",
      "Epoch 2: val_accuracy improved from 0.41546 to 0.56280, saving model to /content/drive/MyDrive/TaheriThesis/Dataset/Multimodal Sentiment/Models_2/resnet.h5\n",
      "120/120 [==============================] - 10s 80ms/step - loss: 1.4883 - accuracy: 0.4480 - val_loss: 1.3569 - val_accuracy: 0.5628\n",
      "Epoch 3/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.0872 - accuracy: 0.6144\n",
      "Epoch 3: val_accuracy improved from 0.56280 to 0.63527, saving model to /content/drive/MyDrive/TaheriThesis/Dataset/Multimodal Sentiment/Models_2/resnet.h5\n",
      "120/120 [==============================] - 10s 80ms/step - loss: 1.0872 - accuracy: 0.6144 - val_loss: 1.1726 - val_accuracy: 0.6353\n",
      "Epoch 4/30\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.6478 - accuracy: 0.7878\n",
      "Epoch 4: val_accuracy did not improve from 0.63527\n",
      "120/120 [==============================] - 9s 72ms/step - loss: 0.6483 - accuracy: 0.7874 - val_loss: 1.6165 - val_accuracy: 0.6111\n",
      "Epoch 5/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.3676 - accuracy: 0.9011\n",
      "Epoch 5: val_accuracy improved from 0.63527 to 0.71256, saving model to /content/drive/MyDrive/TaheriThesis/Dataset/Multimodal Sentiment/Models_2/resnet.h5\n",
      "120/120 [==============================] - 10s 87ms/step - loss: 0.3676 - accuracy: 0.9011 - val_loss: 1.4252 - val_accuracy: 0.7126\n",
      "Epoch 6/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.2523 - accuracy: 0.9293\n",
      "Epoch 6: val_accuracy did not improve from 0.71256\n",
      "120/120 [==============================] - 9s 74ms/step - loss: 0.2523 - accuracy: 0.9293 - val_loss: 1.7563 - val_accuracy: 0.6884\n",
      "Epoch 7/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.1751 - accuracy: 0.9536\n",
      "Epoch 7: val_accuracy improved from 0.71256 to 0.73913, saving model to /content/drive/MyDrive/TaheriThesis/Dataset/Multimodal Sentiment/Models_2/resnet.h5\n",
      "120/120 [==============================] - 11s 93ms/step - loss: 0.1751 - accuracy: 0.9536 - val_loss: 1.4356 - val_accuracy: 0.7391\n",
      "Epoch 8/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.1239 - accuracy: 0.9640\n",
      "Epoch 8: val_accuracy did not improve from 0.73913\n",
      "120/120 [==============================] - 9s 73ms/step - loss: 0.1239 - accuracy: 0.9640 - val_loss: 1.3580 - val_accuracy: 0.7150\n",
      "Epoch 9/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.1186 - accuracy: 0.9650\n",
      "Epoch 9: val_accuracy did not improve from 0.73913\n",
      "120/120 [==============================] - 9s 74ms/step - loss: 0.1186 - accuracy: 0.9650 - val_loss: 1.5126 - val_accuracy: 0.7222\n",
      "Epoch 10/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0963 - accuracy: 0.9703\n",
      "Epoch 10: val_accuracy did not improve from 0.73913\n",
      "120/120 [==============================] - 8s 69ms/step - loss: 0.0963 - accuracy: 0.9703 - val_loss: 1.6248 - val_accuracy: 0.7053\n",
      "Epoch 11/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.1168 - accuracy: 0.9616\n",
      "Epoch 11: val_accuracy did not improve from 0.73913\n",
      "120/120 [==============================] - 9s 73ms/step - loss: 0.1168 - accuracy: 0.9616 - val_loss: 1.7797 - val_accuracy: 0.7319\n",
      "Epoch 12/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.1538 - accuracy: 0.9512\n",
      "Epoch 12: val_accuracy did not improve from 0.73913\n",
      "120/120 [==============================] - 9s 74ms/step - loss: 0.1538 - accuracy: 0.9512 - val_loss: 1.7961 - val_accuracy: 0.6836\n",
      "Epoch 13/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.1519 - accuracy: 0.9468\n",
      "Epoch 13: val_accuracy did not improve from 0.73913\n",
      "120/120 [==============================] - 8s 69ms/step - loss: 0.1519 - accuracy: 0.9468 - val_loss: 1.8364 - val_accuracy: 0.6957\n",
      "Epoch 14/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.1611 - accuracy: 0.9455\n",
      "Epoch 14: val_accuracy did not improve from 0.73913\n",
      "120/120 [==============================] - 9s 74ms/step - loss: 0.1611 - accuracy: 0.9455 - val_loss: 1.9583 - val_accuracy: 0.7174\n",
      "Epoch 15/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.1224 - accuracy: 0.9559\n",
      "Epoch 15: val_accuracy did not improve from 0.73913\n",
      "120/120 [==============================] - 9s 73ms/step - loss: 0.1224 - accuracy: 0.9559 - val_loss: 1.5993 - val_accuracy: 0.7343\n",
      "Epoch 16/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0891 - accuracy: 0.9705\n",
      "Epoch 16: val_accuracy did not improve from 0.73913\n",
      "120/120 [==============================] - 8s 69ms/step - loss: 0.0891 - accuracy: 0.9705 - val_loss: 1.8146 - val_accuracy: 0.7319\n",
      "Epoch 17/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0709 - accuracy: 0.9752\n",
      "Epoch 17: val_accuracy did not improve from 0.73913\n",
      "120/120 [==============================] - 9s 73ms/step - loss: 0.0709 - accuracy: 0.9752 - val_loss: 1.9038 - val_accuracy: 0.7319\n",
      "Epoch 18/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0613 - accuracy: 0.9768\n",
      "Epoch 18: val_accuracy did not improve from 0.73913\n",
      "120/120 [==============================] - 9s 73ms/step - loss: 0.0613 - accuracy: 0.9768 - val_loss: 1.6953 - val_accuracy: 0.7391\n",
      "Epoch 19/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0651 - accuracy: 0.9747\n",
      "Epoch 19: val_accuracy did not improve from 0.73913\n",
      "120/120 [==============================] - 9s 74ms/step - loss: 0.0651 - accuracy: 0.9747 - val_loss: 1.6867 - val_accuracy: 0.7295\n",
      "Epoch 20/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0660 - accuracy: 0.9760\n",
      "Epoch 20: val_accuracy improved from 0.73913 to 0.75362, saving model to /content/drive/MyDrive/TaheriThesis/Dataset/Multimodal Sentiment/Models_2/resnet.h5\n",
      "120/120 [==============================] - 11s 91ms/step - loss: 0.0660 - accuracy: 0.9760 - val_loss: 1.8972 - val_accuracy: 0.7536\n",
      "Epoch 21/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0934 - accuracy: 0.9671\n",
      "Epoch 21: val_accuracy did not improve from 0.75362\n",
      "120/120 [==============================] - 9s 74ms/step - loss: 0.0934 - accuracy: 0.9671 - val_loss: 1.9987 - val_accuracy: 0.7077\n",
      "Epoch 22/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.1188 - accuracy: 0.9590\n",
      "Epoch 22: val_accuracy improved from 0.75362 to 0.75604, saving model to /content/drive/MyDrive/TaheriThesis/Dataset/Multimodal Sentiment/Models_2/resnet.h5\n",
      "120/120 [==============================] - 10s 85ms/step - loss: 0.1188 - accuracy: 0.9590 - val_loss: 1.9951 - val_accuracy: 0.7560\n",
      "Epoch 23/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.1175 - accuracy: 0.9614\n",
      "Epoch 23: val_accuracy did not improve from 0.75604\n",
      "120/120 [==============================] - 8s 69ms/step - loss: 0.1175 - accuracy: 0.9614 - val_loss: 1.8278 - val_accuracy: 0.7005\n",
      "Epoch 24/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.1134 - accuracy: 0.9603\n",
      "Epoch 24: val_accuracy did not improve from 0.75604\n",
      "120/120 [==============================] - 9s 75ms/step - loss: 0.1134 - accuracy: 0.9603 - val_loss: 1.8618 - val_accuracy: 0.7174\n",
      "Epoch 25/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0969 - accuracy: 0.9666\n",
      "Epoch 25: val_accuracy did not improve from 0.75604\n",
      "120/120 [==============================] - 8s 69ms/step - loss: 0.0969 - accuracy: 0.9666 - val_loss: 1.7107 - val_accuracy: 0.6860\n",
      "Epoch 26/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0833 - accuracy: 0.9684\n",
      "Epoch 26: val_accuracy did not improve from 0.75604\n",
      "120/120 [==============================] - 9s 75ms/step - loss: 0.0833 - accuracy: 0.9684 - val_loss: 1.9090 - val_accuracy: 0.7391\n",
      "Epoch 27/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0872 - accuracy: 0.9695\n",
      "Epoch 27: val_accuracy did not improve from 0.75604\n",
      "120/120 [==============================] - 9s 74ms/step - loss: 0.0872 - accuracy: 0.9695 - val_loss: 1.5864 - val_accuracy: 0.7367\n",
      "Epoch 28/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0570 - accuracy: 0.9760\n",
      "Epoch 28: val_accuracy did not improve from 0.75604\n",
      "120/120 [==============================] - 9s 73ms/step - loss: 0.0570 - accuracy: 0.9760 - val_loss: 1.9838 - val_accuracy: 0.7246\n",
      "Epoch 29/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0503 - accuracy: 0.9778\n",
      "Epoch 29: val_accuracy did not improve from 0.75604\n",
      "120/120 [==============================] - 9s 74ms/step - loss: 0.0503 - accuracy: 0.9778 - val_loss: 1.7696 - val_accuracy: 0.7367\n",
      "Epoch 30/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0436 - accuracy: 0.9802\n",
      "Epoch 30: val_accuracy did not improve from 0.75604\n",
      "120/120 [==============================] - 9s 74ms/step - loss: 0.0436 - accuracy: 0.9802 - val_loss: 1.7281 - val_accuracy: 0.7391\n",
      "Model Name: inception\n",
      "\n",
      "Epoch 1/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.9602 - accuracy: 0.2163\n",
      "Epoch 1: val_accuracy improved from -inf to 0.21981, saving model to /content/drive/MyDrive/TaheriThesis/Dataset/Multimodal Sentiment/Models_2/inception.h5\n",
      "120/120 [==============================] - 63s 182ms/step - loss: 1.9602 - accuracy: 0.2163 - val_loss: 12679.9336 - val_accuracy: 0.2198\n",
      "Epoch 2/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.8955 - accuracy: 0.2379\n",
      "Epoch 2: val_accuracy improved from 0.21981 to 0.30676, saving model to /content/drive/MyDrive/TaheriThesis/Dataset/Multimodal Sentiment/Models_2/inception.h5\n",
      "120/120 [==============================] - 15s 128ms/step - loss: 1.8955 - accuracy: 0.2379 - val_loss: 2.0335 - val_accuracy: 0.3068\n",
      "Epoch 3/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.8932 - accuracy: 0.2340\n",
      "Epoch 3: val_accuracy did not improve from 0.30676\n",
      "120/120 [==============================] - 14s 115ms/step - loss: 1.8932 - accuracy: 0.2340 - val_loss: 584.8431 - val_accuracy: 0.2319\n",
      "Epoch 4/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.8877 - accuracy: 0.2442\n",
      "Epoch 4: val_accuracy did not improve from 0.30676\n",
      "120/120 [==============================] - 13s 112ms/step - loss: 1.8877 - accuracy: 0.2442 - val_loss: 29.1467 - val_accuracy: 0.2560\n",
      "Epoch 5/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.8785 - accuracy: 0.2468\n",
      "Epoch 5: val_accuracy did not improve from 0.30676\n",
      "120/120 [==============================] - 13s 110ms/step - loss: 1.8785 - accuracy: 0.2468 - val_loss: 15.8707 - val_accuracy: 0.2754\n",
      "Epoch 6/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.8721 - accuracy: 0.2536\n",
      "Epoch 6: val_accuracy did not improve from 0.30676\n",
      "120/120 [==============================] - 13s 111ms/step - loss: 1.8721 - accuracy: 0.2536 - val_loss: 4.5227 - val_accuracy: 0.2415\n",
      "Epoch 7/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.8751 - accuracy: 0.2570\n",
      "Epoch 7: val_accuracy did not improve from 0.30676\n",
      "120/120 [==============================] - 13s 111ms/step - loss: 1.8751 - accuracy: 0.2570 - val_loss: 73.0343 - val_accuracy: 0.2053\n",
      "Epoch 8/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.8776 - accuracy: 0.2617\n",
      "Epoch 8: val_accuracy did not improve from 0.30676\n",
      "120/120 [==============================] - 13s 111ms/step - loss: 1.8776 - accuracy: 0.2617 - val_loss: 2.1366 - val_accuracy: 0.1787\n",
      "Epoch 9/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.8732 - accuracy: 0.2567\n",
      "Epoch 9: val_accuracy did not improve from 0.30676\n",
      "120/120 [==============================] - 13s 111ms/step - loss: 1.8732 - accuracy: 0.2567 - val_loss: 708.7503 - val_accuracy: 0.2367\n",
      "Epoch 10/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.8551 - accuracy: 0.2622\n",
      "Epoch 10: val_accuracy did not improve from 0.30676\n",
      "120/120 [==============================] - 14s 114ms/step - loss: 1.8551 - accuracy: 0.2622 - val_loss: 5.3186 - val_accuracy: 0.2705\n",
      "Epoch 11/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.8417 - accuracy: 0.2747\n",
      "Epoch 11: val_accuracy did not improve from 0.30676\n",
      "120/120 [==============================] - 13s 112ms/step - loss: 1.8417 - accuracy: 0.2747 - val_loss: 3.1695 - val_accuracy: 0.2802\n",
      "Epoch 12/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.8244 - accuracy: 0.2951\n",
      "Epoch 12: val_accuracy did not improve from 0.30676\n",
      "120/120 [==============================] - 13s 112ms/step - loss: 1.8244 - accuracy: 0.2951 - val_loss: 2.0728 - val_accuracy: 0.2657\n",
      "Epoch 13/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.8121 - accuracy: 0.2885\n",
      "Epoch 13: val_accuracy did not improve from 0.30676\n",
      "120/120 [==============================] - 13s 112ms/step - loss: 1.8121 - accuracy: 0.2885 - val_loss: 8.9054 - val_accuracy: 0.2923\n",
      "Epoch 14/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.7974 - accuracy: 0.3063\n",
      "Epoch 14: val_accuracy did not improve from 0.30676\n",
      "120/120 [==============================] - 14s 114ms/step - loss: 1.7974 - accuracy: 0.3063 - val_loss: 5.0795 - val_accuracy: 0.3068\n",
      "Epoch 15/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.7954 - accuracy: 0.3097\n",
      "Epoch 15: val_accuracy did not improve from 0.30676\n",
      "120/120 [==============================] - 14s 114ms/step - loss: 1.7954 - accuracy: 0.3097 - val_loss: 7.0485 - val_accuracy: 0.2874\n",
      "Epoch 16/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.7612 - accuracy: 0.3146\n",
      "Epoch 16: val_accuracy did not improve from 0.30676\n",
      "120/120 [==============================] - 14s 114ms/step - loss: 1.7612 - accuracy: 0.3146 - val_loss: 6.5553 - val_accuracy: 0.2246\n",
      "Epoch 17/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.7101 - accuracy: 0.3394\n",
      "Epoch 17: val_accuracy did not improve from 0.30676\n",
      "120/120 [==============================] - 13s 112ms/step - loss: 1.7101 - accuracy: 0.3394 - val_loss: 2.5239 - val_accuracy: 0.2729\n",
      "Epoch 18/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.6763 - accuracy: 0.3538\n",
      "Epoch 18: val_accuracy did not improve from 0.30676\n",
      "120/120 [==============================] - 14s 114ms/step - loss: 1.6763 - accuracy: 0.3538 - val_loss: 2.0162 - val_accuracy: 0.2633\n",
      "Epoch 19/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.6231 - accuracy: 0.3765\n",
      "Epoch 19: val_accuracy did not improve from 0.30676\n",
      "120/120 [==============================] - 14s 114ms/step - loss: 1.6231 - accuracy: 0.3765 - val_loss: 2.2988 - val_accuracy: 0.2995\n",
      "Epoch 20/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.5742 - accuracy: 0.3947\n",
      "Epoch 20: val_accuracy did not improve from 0.30676\n",
      "120/120 [==============================] - 13s 113ms/step - loss: 1.5742 - accuracy: 0.3947 - val_loss: 2.4308 - val_accuracy: 0.2560\n",
      "Epoch 21/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.5358 - accuracy: 0.4153\n",
      "Epoch 21: val_accuracy did not improve from 0.30676\n",
      "120/120 [==============================] - 14s 114ms/step - loss: 1.5358 - accuracy: 0.4153 - val_loss: 1.8227 - val_accuracy: 0.2778\n",
      "Epoch 22/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.4806 - accuracy: 0.4344\n",
      "Epoch 22: val_accuracy did not improve from 0.30676\n",
      "120/120 [==============================] - 14s 114ms/step - loss: 1.4806 - accuracy: 0.4344 - val_loss: 4.9508 - val_accuracy: 0.2850\n",
      "Epoch 23/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.4376 - accuracy: 0.4487\n",
      "Epoch 23: val_accuracy did not improve from 0.30676\n",
      "120/120 [==============================] - 14s 114ms/step - loss: 1.4376 - accuracy: 0.4487 - val_loss: 2.4846 - val_accuracy: 0.2271\n",
      "Epoch 24/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.4862 - accuracy: 0.4320\n",
      "Epoch 24: val_accuracy improved from 0.30676 to 0.32850, saving model to /content/drive/MyDrive/TaheriThesis/Dataset/Multimodal Sentiment/Models_2/inception.h5\n",
      "120/120 [==============================] - 17s 143ms/step - loss: 1.4862 - accuracy: 0.4320 - val_loss: 2.1190 - val_accuracy: 0.3285\n",
      "Epoch 25/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.4092 - accuracy: 0.4558\n",
      "Epoch 25: val_accuracy improved from 0.32850 to 0.37681, saving model to /content/drive/MyDrive/TaheriThesis/Dataset/Multimodal Sentiment/Models_2/inception.h5\n",
      "120/120 [==============================] - 16s 133ms/step - loss: 1.4092 - accuracy: 0.4558 - val_loss: 2.3635 - val_accuracy: 0.3768\n",
      "Epoch 26/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.3212 - accuracy: 0.4907\n",
      "Epoch 26: val_accuracy did not improve from 0.37681\n",
      "120/120 [==============================] - 14s 117ms/step - loss: 1.3212 - accuracy: 0.4907 - val_loss: 1.6771 - val_accuracy: 0.3575\n",
      "Epoch 27/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.2250 - accuracy: 0.5218\n",
      "Epoch 27: val_accuracy improved from 0.37681 to 0.41063, saving model to /content/drive/MyDrive/TaheriThesis/Dataset/Multimodal Sentiment/Models_2/inception.h5\n",
      "120/120 [==============================] - 17s 144ms/step - loss: 1.2250 - accuracy: 0.5218 - val_loss: 1.7471 - val_accuracy: 0.4106\n",
      "Epoch 28/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.1636 - accuracy: 0.5547\n",
      "Epoch 28: val_accuracy did not improve from 0.41063\n",
      "120/120 [==============================] - 14s 115ms/step - loss: 1.1636 - accuracy: 0.5547 - val_loss: 1.9117 - val_accuracy: 0.4082\n",
      "Epoch 29/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.1441 - accuracy: 0.5578\n",
      "Epoch 29: val_accuracy improved from 0.41063 to 0.43237, saving model to /content/drive/MyDrive/TaheriThesis/Dataset/Multimodal Sentiment/Models_2/inception.h5\n",
      "120/120 [==============================] - 17s 146ms/step - loss: 1.1441 - accuracy: 0.5578 - val_loss: 1.6299 - val_accuracy: 0.4324\n",
      "Epoch 30/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.1160 - accuracy: 0.5758\n",
      "Epoch 30: val_accuracy did not improve from 0.43237\n",
      "120/120 [==============================] - 14s 116ms/step - loss: 1.1160 - accuracy: 0.5758 - val_loss: 7.1493 - val_accuracy: 0.3478\n",
      "Model Name: densenet\n",
      "\n",
      "Epoch 1/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 2.0784 - accuracy: 0.2092\n",
      "Epoch 1: val_accuracy improved from -inf to 0.22464, saving model to /content/drive/MyDrive/TaheriThesis/Dataset/Multimodal Sentiment/Models_2/densenet.h5\n",
      "120/120 [==============================] - 107s 281ms/step - loss: 2.0784 - accuracy: 0.2092 - val_loss: 2.0177 - val_accuracy: 0.2246\n",
      "Epoch 2/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.9626 - accuracy: 0.2181\n",
      "Epoch 2: val_accuracy did not improve from 0.22464\n",
      "120/120 [==============================] - 23s 192ms/step - loss: 1.9626 - accuracy: 0.2181 - val_loss: 8.2364 - val_accuracy: 0.1667\n",
      "Epoch 3/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.9426 - accuracy: 0.2165\n",
      "Epoch 3: val_accuracy did not improve from 0.22464\n",
      "120/120 [==============================] - 23s 189ms/step - loss: 1.9426 - accuracy: 0.2165 - val_loss: 6.1067 - val_accuracy: 0.1739\n",
      "Epoch 4/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.9248 - accuracy: 0.2254\n",
      "Epoch 4: val_accuracy improved from 0.22464 to 0.22947, saving model to /content/drive/MyDrive/TaheriThesis/Dataset/Multimodal Sentiment/Models_2/densenet.h5\n",
      "120/120 [==============================] - 26s 215ms/step - loss: 1.9248 - accuracy: 0.2254 - val_loss: 2.0232 - val_accuracy: 0.2295\n",
      "Epoch 5/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.9280 - accuracy: 0.2228\n",
      "Epoch 5: val_accuracy did not improve from 0.22947\n",
      "120/120 [==============================] - 23s 189ms/step - loss: 1.9280 - accuracy: 0.2228 - val_loss: 223.1753 - val_accuracy: 0.2271\n",
      "Epoch 6/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.9282 - accuracy: 0.2296\n",
      "Epoch 6: val_accuracy did not improve from 0.22947\n",
      "120/120 [==============================] - 23s 189ms/step - loss: 1.9282 - accuracy: 0.2296 - val_loss: 10.4421 - val_accuracy: 0.1932\n",
      "Epoch 7/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.9128 - accuracy: 0.2304\n",
      "Epoch 7: val_accuracy improved from 0.22947 to 0.24879, saving model to /content/drive/MyDrive/TaheriThesis/Dataset/Multimodal Sentiment/Models_2/densenet.h5\n",
      "120/120 [==============================] - 26s 214ms/step - loss: 1.9128 - accuracy: 0.2304 - val_loss: 1.8499 - val_accuracy: 0.2488\n",
      "Epoch 8/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.9031 - accuracy: 0.2434\n",
      "Epoch 8: val_accuracy did not improve from 0.24879\n",
      "120/120 [==============================] - 23s 190ms/step - loss: 1.9031 - accuracy: 0.2434 - val_loss: 1.9381 - val_accuracy: 0.2415\n",
      "Epoch 9/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.9376 - accuracy: 0.2189\n",
      "Epoch 9: val_accuracy did not improve from 0.24879\n",
      "120/120 [==============================] - 23s 190ms/step - loss: 1.9376 - accuracy: 0.2189 - val_loss: 2.9145 - val_accuracy: 0.2126\n",
      "Epoch 10/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.9112 - accuracy: 0.2387\n",
      "Epoch 10: val_accuracy did not improve from 0.24879\n",
      "120/120 [==============================] - 23s 189ms/step - loss: 1.9112 - accuracy: 0.2387 - val_loss: 1.8975 - val_accuracy: 0.1860\n",
      "Epoch 11/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.8936 - accuracy: 0.2452\n",
      "Epoch 11: val_accuracy improved from 0.24879 to 0.25604, saving model to /content/drive/MyDrive/TaheriThesis/Dataset/Multimodal Sentiment/Models_2/densenet.h5\n",
      "120/120 [==============================] - 26s 215ms/step - loss: 1.8936 - accuracy: 0.2452 - val_loss: 3.6546 - val_accuracy: 0.2560\n",
      "Epoch 12/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.8935 - accuracy: 0.2476\n",
      "Epoch 12: val_accuracy improved from 0.25604 to 0.25845, saving model to /content/drive/MyDrive/TaheriThesis/Dataset/Multimodal Sentiment/Models_2/densenet.h5\n",
      "120/120 [==============================] - 26s 214ms/step - loss: 1.8935 - accuracy: 0.2476 - val_loss: 2.3293 - val_accuracy: 0.2585\n",
      "Epoch 13/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.8858 - accuracy: 0.2510\n",
      "Epoch 13: val_accuracy improved from 0.25845 to 0.26570, saving model to /content/drive/MyDrive/TaheriThesis/Dataset/Multimodal Sentiment/Models_2/densenet.h5\n",
      "120/120 [==============================] - 26s 216ms/step - loss: 1.8858 - accuracy: 0.2510 - val_loss: 1.7922 - val_accuracy: 0.2657\n",
      "Epoch 14/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.8781 - accuracy: 0.2505\n",
      "Epoch 14: val_accuracy did not improve from 0.26570\n",
      "120/120 [==============================] - 23s 188ms/step - loss: 1.8781 - accuracy: 0.2505 - val_loss: 3.6018 - val_accuracy: 0.2222\n",
      "Epoch 15/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.8881 - accuracy: 0.2452\n",
      "Epoch 15: val_accuracy did not improve from 0.26570\n",
      "120/120 [==============================] - 23s 189ms/step - loss: 1.8881 - accuracy: 0.2452 - val_loss: 2.0758 - val_accuracy: 0.2512\n",
      "Epoch 16/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.8878 - accuracy: 0.2408\n",
      "Epoch 16: val_accuracy improved from 0.26570 to 0.29469, saving model to /content/drive/MyDrive/TaheriThesis/Dataset/Multimodal Sentiment/Models_2/densenet.h5\n",
      "120/120 [==============================] - 26s 213ms/step - loss: 1.8878 - accuracy: 0.2408 - val_loss: 2.5713 - val_accuracy: 0.2947\n",
      "Epoch 17/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.8765 - accuracy: 0.2630\n",
      "Epoch 17: val_accuracy improved from 0.29469 to 0.35266, saving model to /content/drive/MyDrive/TaheriThesis/Dataset/Multimodal Sentiment/Models_2/densenet.h5\n",
      "120/120 [==============================] - 26s 213ms/step - loss: 1.8765 - accuracy: 0.2630 - val_loss: 1.7393 - val_accuracy: 0.3527\n",
      "Epoch 18/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.8652 - accuracy: 0.2625\n",
      "Epoch 18: val_accuracy did not improve from 0.35266\n",
      "120/120 [==============================] - 23s 190ms/step - loss: 1.8652 - accuracy: 0.2625 - val_loss: 1.8216 - val_accuracy: 0.2560\n",
      "Epoch 19/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.8563 - accuracy: 0.2661\n",
      "Epoch 19: val_accuracy did not improve from 0.35266\n",
      "120/120 [==============================] - 23s 189ms/step - loss: 1.8563 - accuracy: 0.2661 - val_loss: 1.8302 - val_accuracy: 0.2246\n",
      "Epoch 20/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.8541 - accuracy: 0.2630\n",
      "Epoch 20: val_accuracy did not improve from 0.35266\n",
      "120/120 [==============================] - 23s 193ms/step - loss: 1.8541 - accuracy: 0.2630 - val_loss: 1.7589 - val_accuracy: 0.3068\n",
      "Epoch 21/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.8494 - accuracy: 0.2585\n",
      "Epoch 21: val_accuracy did not improve from 0.35266\n",
      "120/120 [==============================] - 23s 193ms/step - loss: 1.8494 - accuracy: 0.2585 - val_loss: 3.0885 - val_accuracy: 0.2681\n",
      "Epoch 22/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.8564 - accuracy: 0.2617\n",
      "Epoch 22: val_accuracy did not improve from 0.35266\n",
      "120/120 [==============================] - 23s 188ms/step - loss: 1.8564 - accuracy: 0.2617 - val_loss: 3.9662 - val_accuracy: 0.2053\n",
      "Epoch 23/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.8656 - accuracy: 0.2575\n",
      "Epoch 23: val_accuracy did not improve from 0.35266\n",
      "120/120 [==============================] - 23s 189ms/step - loss: 1.8656 - accuracy: 0.2575 - val_loss: 2.0911 - val_accuracy: 0.2778\n",
      "Epoch 24/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.8424 - accuracy: 0.2661\n",
      "Epoch 24: val_accuracy did not improve from 0.35266\n",
      "120/120 [==============================] - 23s 190ms/step - loss: 1.8424 - accuracy: 0.2661 - val_loss: 1.8277 - val_accuracy: 0.2391\n",
      "Epoch 25/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.8260 - accuracy: 0.2841\n",
      "Epoch 25: val_accuracy did not improve from 0.35266\n",
      "120/120 [==============================] - 23s 190ms/step - loss: 1.8260 - accuracy: 0.2841 - val_loss: 1.7390 - val_accuracy: 0.2560\n",
      "Epoch 26/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.8268 - accuracy: 0.2839\n",
      "Epoch 26: val_accuracy did not improve from 0.35266\n",
      "120/120 [==============================] - 23s 189ms/step - loss: 1.8268 - accuracy: 0.2839 - val_loss: 2.2664 - val_accuracy: 0.3092\n",
      "Epoch 27/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.8468 - accuracy: 0.2732\n",
      "Epoch 27: val_accuracy did not improve from 0.35266\n",
      "120/120 [==============================] - 23s 188ms/step - loss: 1.8468 - accuracy: 0.2732 - val_loss: 3.3762 - val_accuracy: 0.1981\n",
      "Epoch 28/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.8540 - accuracy: 0.2752\n",
      "Epoch 28: val_accuracy did not improve from 0.35266\n",
      "120/120 [==============================] - 23s 189ms/step - loss: 1.8540 - accuracy: 0.2752 - val_loss: 2.3679 - val_accuracy: 0.1836\n",
      "Epoch 29/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.8496 - accuracy: 0.2672\n",
      "Epoch 29: val_accuracy did not improve from 0.35266\n",
      "120/120 [==============================] - 23s 189ms/step - loss: 1.8496 - accuracy: 0.2672 - val_loss: 1.7254 - val_accuracy: 0.3164\n",
      "Epoch 30/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.8161 - accuracy: 0.2820\n",
      "Epoch 30: val_accuracy did not improve from 0.35266\n",
      "120/120 [==============================] - 23s 189ms/step - loss: 1.8161 - accuracy: 0.2820 - val_loss: 2.1955 - val_accuracy: 0.2729\n"
     ]
    }
   ],
   "source": [
    "model_name = ['resnet']\n",
    "list_model = visual_models()\n",
    "\n",
    "for mn,model in enumerate(list_model):\n",
    "\n",
    "  model.compile(loss='categorical_crossentropy', \n",
    "                      optimizer=Adam()\n",
    ", \n",
    "                      metrics = [\"accuracy\"])\n",
    "  print(f\"Model Name: {model_name[mn]}\\n\")\n",
    "  # Training model\n",
    "  model.fit(x=train_image, \n",
    "              y=y_train,\n",
    "              epochs=30, \n",
    "              batch_size =32,\n",
    "              validation_data=(valid_image,y_valid),\n",
    "              verbose = 1,\n",
    "              class_weight = class_weights,\n",
    "              callbacks = callbacks_check(model_name[mn])\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U543x2hvaEI9"
   },
   "source": [
    "## Visual Models Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "WbQQnBNkaEJA"
   },
   "outputs": [],
   "source": [
    "visual_models = ['resnet',]\n",
    "visual_model_names = ['ResNet']\n",
    "\n",
    "def visual_models_accuracy(saved_model): \n",
    "  my_dict = {}\n",
    "  # Prediction \n",
    "  model = load_model(models_path+'Models_2/'+f\"{saved_model}.h5\")\n",
    "  y_pred = np.argmax(model.predict(test_image), axis=-1)\n",
    "\n",
    "  y_true = test_data['enc_label']\n",
    "\n",
    "  my_dict['Accuracy'] = accuracy_score(y_true, y_pred)*100\n",
    "  my_dict['Precision'] = precision_score(y_true, y_pred,average = 'weighted')*100\n",
    "  my_dict['Recall'] = recall_score(y_true, y_pred,average = 'weighted')*100 \n",
    "  my_dict['F1 Score'] = f1_score(y_true, y_pred,average = 'weighted')*100 \n",
    "  return my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ifFG2vO9aEJB",
    "outputId": "51e37d94-8520-4394-a7ad-c799faa58161"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 19s 1s/step\n"
     ]
    }
   ],
   "source": [
    "accuracy = {f'{visual_model_names[i]}':visual_models_accuracy(model) for i,model in enumerate(visual_models)}\n",
    "# Save the performance parameter into json file\n",
    "with open(models_path+'Results_2/'+'visual_models_performance.json', 'w') as f:\n",
    "    json.dump(accuracy, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 116
    },
    "id": "p3eIUlFy09qo",
    "outputId": "152d680a-1420-475c-a58d-887695c6173a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m=======  Visual Models Performance on Test Data  =============\n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-d00a7726-b82f-47be-89f5-7ce054dc5cb2\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ResNet</th>\n",
       "      <td>70.53</td>\n",
       "      <td>73.36</td>\n",
       "      <td>70.53</td>\n",
       "      <td>70.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d00a7726-b82f-47be-89f5-7ce054dc5cb2')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-d00a7726-b82f-47be-89f5-7ce054dc5cb2 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-d00a7726-b82f-47be-89f5-7ce054dc5cb2');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "        Accuracy  Precision  Recall  F1 Score\n",
       "ResNet     70.53      73.36   70.53     70.36"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the json file\n",
    "metrics = json.load(open(models_path+'Results_2/'+'visual_models_performance.json'))\n",
    "acc_list = []\n",
    "pr_list = []\n",
    "re_list = []\n",
    "f1_list = []\n",
    "for i in metrics.keys():\n",
    "  acc_list.append(round(metrics[i]['Accuracy'],2))\n",
    "  pr_list.append(round(metrics[i]['Precision'],2))\n",
    "  re_list.append(round(metrics[i]['Recall'],2))\n",
    "  f1_list.append(round(metrics[i]['F1 Score'],2))\n",
    "\n",
    "print (color.BOLD+f\"=======  Visual Models Performance on Test Data  =============\\n\"+color.END)\n",
    "# Create a dataframe\n",
    "performance_matrix = pd.DataFrame({'Accuracy':acc_list,'Precision':pr_list,\n",
    "                                   'Recall':re_list,'F1 Score':f1_list},\n",
    "                                  index =['ResNet'])\n",
    "performance_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oV4hkM1ybA2y"
   },
   "source": [
    "## Confusion Matrix (Visual Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "l42SMBKYhQwz"
   },
   "outputs": [],
   "source": [
    "visual_models = ['resnet']\n",
    "visual_model_names = ['ResNet']\n",
    "class_names = ['happy','angry','disgust','fear','sad','surprise','other']\n",
    "def visual_models_confusion_matrix(saved_model,model_name): \n",
    "   \n",
    "  model = load_model(models_path+'Models_2/'+f\"{saved_model}.h5\")\n",
    "  y_pred = np.argmax(model.predict(test_image), axis=-1)\n",
    "\n",
    "  y_true = test_data['enc_label']\n",
    "  con_mat(y_true,y_pred,class_names,model_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "id": "Y50NUbd3bA3S",
    "outputId": "335c8995-3294-4b7a-80e2-6cfbd0fc20c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m======= Confusion Matrices for Visual Models  =============\n",
      "\u001b[0m\n",
      "13/13 [==============================] - 21s 2s/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 400x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print (color.BOLD+f\"======= Confusion Matrices for Visual Models  =============\\n\"+color.END)\n",
    "for i,model in enumerate(visual_models):\n",
    "  visual_models_confusion_matrix(model,visual_model_names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "jlkszFX8izIv"
   },
   "outputs": [],
   "source": [
    "visual_models = ['resnet']\n",
    "visual_model_names = ['ResNet']\n",
    "class_names = ['happy','angry','disgust','fear','sad','surprise','other']\n",
    "def visual_models_metrics(saved_model,model_name): \n",
    "   \n",
    "  model = load_model(models_path+'Models_2/'+f\"{saved_model}.h5\")\n",
    "  y_pred = np.argmax(model.predict(test_image), axis=-1)\n",
    "\n",
    "  y_true = test_data['enc_label']\n",
    "  # con_mat(y_true,y_pred,class_names,model_name) \n",
    "  print_metrices(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YF8HzXJUkbW9",
    "outputId": "b5ebdf54-75c1-4f22-c728-3fe8809f3ce4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m======= Matrices for Visual Models  =============\n",
      "\u001b[0m\n",
      "13/13 [==============================] - 27s 2s/step\n",
      "[[81  1  3  2  4  1  1]\n",
      " [ 6 31  3  0  3  0  1]\n",
      " [ 3  3 29  1  0  1  3]\n",
      " [ 6  1  2 32  0  1  2]\n",
      " [14  1  1  1 50  0  1]\n",
      " [13  0  1  3  5 24  1]\n",
      " [14  5  3  0 10  1 45]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.87      0.70        93\n",
      "           1       0.74      0.70      0.72        44\n",
      "           2       0.69      0.72      0.71        40\n",
      "           3       0.82      0.73      0.77        44\n",
      "           4       0.69      0.74      0.71        68\n",
      "           5       0.86      0.51      0.64        47\n",
      "           6       0.83      0.58      0.68        78\n",
      "\n",
      "    accuracy                           0.71       414\n",
      "   macro avg       0.75      0.69      0.71       414\n",
      "weighted avg       0.73      0.71      0.70       414\n",
      "\n",
      "Accuracy :  0.7053140096618358\n",
      "Precison :  0.7335534786608521\n",
      "Recall :  0.7053140096618358\n",
      "F1 :  0.7035722671065089\n"
     ]
    }
   ],
   "source": [
    "print (color.BOLD+f\"======= Matrices for Visual Models  =============\\n\"+color.END)\n",
    "for i,model in enumerate(visual_models):\n",
    "  visual_models_metrics(model,visual_model_names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DwOAtpKwlTFw",
    "outputId": "092c8bcc-3c28-4bf3-b0e4-d30afb095bb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m======= Matrices for Visual Models  =============\u001b[0m\n",
      "13/13 [==============================] - 22s 2s/step\n",
      "MCC for ResNet: 0.6535726347748353\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "visual_models = [ 'resnet']\n",
    "visual_model_names = [ 'ResNet']\n",
    "class_names = ['happy', 'angry', 'disgust', 'fear', 'sad', 'surprise', 'other']\n",
    "\n",
    "def visual_models_metrics_MCC(saved_model, model_name):\n",
    "  model = load_model(models_path + 'Models_2/' + f\"{saved_model}.h5\")\n",
    "  y_pred = np.argmax(model.predict(test_image), axis=-1)\n",
    "  y_true = test_data['enc_label']\n",
    "\n",
    " \n",
    "\n",
    "  # Calculate MCC\n",
    "  mcc = matthews_corrcoef(y_true, y_pred)\n",
    "  print(f\"MCC for {model_name}: {mcc}\")\n",
    "\n",
    "print(f\"{color.BOLD}======= Matrices for Visual Models  ============={color.END}\")\n",
    "for i, model in enumerate(visual_models):\n",
    "  visual_models_metrics_MCC(model, visual_model_names[i])\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
