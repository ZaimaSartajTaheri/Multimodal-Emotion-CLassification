{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/eftekhar-hossain/Disaster_IEEE-Access/blob/main/damage_identification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D09VDHN9xiww"
   },
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in ./.local/lib/python3.10/site-packages (0.12.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.17 in ./miniconda3/envs/tensorflow/lib/python3.10/site-packages (from seaborn) (1.23.5)\n",
      "Requirement already satisfied: pandas>=0.25 in ./.local/lib/python3.10/site-packages (from seaborn) (2.0.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in ./.local/lib/python3.10/site-packages (from seaborn) (3.7.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.40.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./miniconda3/envs/tensorflow/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in ./.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./miniconda3/envs/tensorflow/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./miniconda3/envs/tensorflow/lib/python3.10/site-packages (from pandas>=0.25->seaborn) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./.local/lib/python3.10/site-packages (from pandas>=0.25->seaborn) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in ./miniconda3/envs/tensorflow/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install seaborn --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in ./miniconda3/envs/tensorflow/lib/python3.10/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in ./miniconda3/envs/tensorflow/lib/python3.10/site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: joblib in ./miniconda3/envs/tensorflow/lib/python3.10/site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./miniconda3/envs/tensorflow/lib/python3.10/site-packages (from nltk) (2023.5.5)\n",
      "Requirement already satisfied: tqdm in ./miniconda3/envs/tensorflow/lib/python3.10/site-packages (from nltk) (4.65.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in ./miniconda3/lib/python3.10/site-packages (3.5.4)\n",
      "Collecting spacy\n",
      "  Downloading spacy-3.6.0-cp310-cp310-macosx_11_0_arm64.whl (6.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: smart-open<7.0.0,>=5.2.1 in ./miniconda3/lib/python3.10/site-packages (from spacy) (6.3.0)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in ./miniconda3/lib/python3.10/site-packages (from spacy) (0.7.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in ./miniconda3/lib/python3.10/site-packages (from spacy) (2.4.6)\n",
      "Requirement already satisfied: setuptools in ./miniconda3/lib/python3.10/site-packages (from spacy) (65.6.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in ./miniconda3/lib/python3.10/site-packages (from spacy) (4.65.0)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in ./miniconda3/lib/python3.10/site-packages (from spacy) (8.1.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in ./miniconda3/lib/python3.10/site-packages (from spacy) (1.1.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in ./miniconda3/lib/python3.10/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: jinja2 in ./miniconda3/lib/python3.10/site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in ./miniconda3/lib/python3.10/site-packages (from spacy) (2.28.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in ./miniconda3/lib/python3.10/site-packages (from spacy) (1.0.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./miniconda3/lib/python3.10/site-packages (from spacy) (23.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in ./miniconda3/lib/python3.10/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in ./miniconda3/lib/python3.10/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: pathy>=0.10.0 in ./miniconda3/lib/python3.10/site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./miniconda3/lib/python3.10/site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: numpy>=1.15.0 in ./miniconda3/lib/python3.10/site-packages (from spacy) (1.24.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in ./miniconda3/lib/python3.10/site-packages (from spacy) (1.10.8)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./miniconda3/lib/python3.10/site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./miniconda3/lib/python3.10/site-packages (from spacy) (1.0.9)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in ./miniconda3/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.5.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./miniconda3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./miniconda3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in ./miniconda3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./miniconda3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.5.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in ./miniconda3/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in ./miniconda3/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.0.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in ./miniconda3/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./miniconda3/lib/python3.10/site-packages (from jinja2->spacy) (2.1.1)\n",
      "Installing collected packages: spacy\n",
      "  Attempting uninstall: spacy\n",
      "    Found existing installation: spacy 3.5.4\n",
      "    Uninstalling spacy-3.5.4:\n",
      "      Successfully uninstalled spacy-3.5.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "en-core-web-sm 3.5.0 requires spacy<3.6.0,>=3.5.0, but you have spacy 3.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed spacy-3.6.0\n",
      "Collecting en-core-web-sm==3.6.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.6.0/en_core_web_sm-3.6.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m883.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in ./miniconda3/lib/python3.10/site-packages (from en-core-web-sm==3.6.0) (3.6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./miniconda3/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (23.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in ./miniconda3/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (6.3.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in ./miniconda3/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.10.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in ./miniconda3/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.1.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in ./miniconda3/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.24.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./miniconda3/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.9)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in ./miniconda3/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.12)\n",
      "Requirement already satisfied: jinja2 in ./miniconda3/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.1.2)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in ./miniconda3/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.10)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in ./miniconda3/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.4)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./miniconda3/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.8)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./miniconda3/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.7)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in ./miniconda3/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.10.8)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in ./miniconda3/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.4.6)\n",
      "Requirement already satisfied: setuptools in ./miniconda3/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (65.6.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in ./miniconda3/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.8)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in ./miniconda3/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.0)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in ./miniconda3/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.7.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in ./miniconda3/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in ./miniconda3/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.28.1)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in ./miniconda3/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in ./miniconda3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./miniconda3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.26.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./miniconda3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./miniconda3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2023.5.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in ./miniconda3/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in ./miniconda3/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.0.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in ./miniconda3/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./miniconda3/lib/python3.10/site-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.1.1)\n",
      "Installing collected packages: en-core-web-sm\n",
      "  Attempting uninstall: en-core-web-sm\n",
      "    Found existing installation: en-core-web-sm 3.5.0\n",
      "    Uninstalling en-core-web-sm-3.5.0:\n",
      "      Successfully uninstalled en-core-web-sm-3.5.0\n",
      "Successfully installed en-core-web-sm-3.6.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install -U spacy\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in ./miniconda3/envs/tensorflow/lib/python3.10/site-packages (1.2.2)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.3.0-cp310-cp310-macosx_12_0_arm64.whl (9.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.3 in ./miniconda3/envs/tensorflow/lib/python3.10/site-packages (from scikit-learn) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.5.0 in ./miniconda3/envs/tensorflow/lib/python3.10/site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in ./miniconda3/envs/tensorflow/lib/python3.10/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./miniconda3/envs/tensorflow/lib/python3.10/site-packages (from scikit-learn) (3.1.0)\n",
      "Installing collected packages: scikit-learn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.2.2\n",
      "    Uninstalling scikit-learn-1.2.2:\n",
      "      Successfully uninstalled scikit-learn-1.2.2\n",
      "Successfully installed scikit-learn-1.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6OdpHrd7yReb",
    "outputId": "b43f07ee-ab4e-4c65-9674-b4e01a7b908d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/zaima/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.79 s, sys: 779 ms, total: 6.57 s\n",
      "Wall time: 16.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import re,nltk,json\n",
    "from sklearn.metrics import confusion_matrix,classification_report \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,roc_auc_score\n",
    "from sklearn.metrics import average_precision_score,roc_auc_score, roc_curve, precision_recall_curve\n",
    "from keras.utils.vis_utils import plot_model\n",
    "np.random.seed(42)\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import ToktokTokenizer\n",
    "import string, spacy,unicodedata, random\n",
    "from bs4 import BeautifulSoup\n",
    "class color: # Text style\n",
    "   PURPLE = '\\033[95m'\n",
    "   CYAN = '\\033[96m'\n",
    "   DARKCYAN = '\\033[36m'\n",
    "   BLUE = '\\033[94m'\n",
    "   GREEN = '\\033[92m'\n",
    "   YELLOW = '\\033[93m'\n",
    "   RED = '\\033[91m'\n",
    "   BOLD = '\\033[1m'\n",
    "   UNDERLINE = '\\033[4m'\n",
    "   END = '\\033[0m'\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "### Pretrained Word Embeddings\n",
    "# pretrained_path = \"/content/drive/MyDrive/TaheriThesis/Dataset/PreTrained Wordembedding/\"\n",
    "# dataset_path = \"/content/drive/MyDrive/Colab Notebooks/MSC Presentation Tasks/Disaster Response/Images/\"\n",
    "# folder_path = \"/content/drive/MyDrive/Colab Notebooks/MSC Presentation Tasks/Disaster Response/\"\n",
    "models_path = \"/Users/zaima/Desktop/Dataset/Multimodal Sentiment/\"\n",
    "\n",
    "\n",
    "folder_path = \"/Users/zaima/Desktop/Dataset/\"\n",
    "# models_path = \"/content/drive/MyDrive/TaheriThesis/Dataset/Multimodal Sentiment/Models/\"\n",
    "# results_path = \"/content/drive/MyDrive/TaheriThesis/Dataset/Multimodal Sentiment/Results/\"\n",
    "dataset_path = \"/Users/zaima/Desktop/Dataset/Images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "l767bYFbGNLf"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Embedding, LSTM, multiply\n",
    "from keras.models import Model\n",
    "from keras import preprocessing, Input\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "#Import from keras_preprocessing not from keras.preprocessing\n",
    "# from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import regularizers, optimizers\n",
    "from tensorflow.keras.models import load_model\n",
    "import itertools\n",
    "from PIL import Image, ImageFile\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Concatenate, Dense, Input, LSTM, Embedding, Dropout, Activation, GRU, Flatten\n",
    "from tensorflow.keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Convolution1D,MaxPooling1D,Conv1D\n",
    "from tensorflow.keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from tensorflow.keras.layers import Add, BatchNormalization, Activation, Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop,Adam,SGD,Nadam\n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jjImoyXizNSk"
   },
   "source": [
    "#Fetching Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "nt9hWjXNzQxq"
   },
   "outputs": [],
   "source": [
    "# train_data = pd.read_excel(folder_path+'train.xlsx')\n",
    "# test_data = pd.read_csv(folder_path+'test.xlsx')\n",
    "# valid_data = pd.read_excel(main_path+'valid_new.xlsx')\n",
    "train_data = pd.read_csv(folder_path+'train.csv')\n",
    "valid_data = pd.read_csv(folder_path+'val.csv')\n",
    "test_data = pd.read_csv(folder_path+'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1lDAsGYgMs8r",
    "outputId": "15ccd733-54f2-4de3-c8af-f2ebab32d79c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['image_name', 'Captions', 'Label_Sentiment', 'Label'], dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RhUgGvUa2WFX",
    "outputId": "9eb394aa-1919-4c1c-c686-726e9174188c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "0    861\n",
       "6    716\n",
       "4    623\n",
       "1    477\n",
       "5    408\n",
       "3    400\n",
       "2    348\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nPO59gZr2c5p",
    "outputId": "df011e8e-766c-4aeb-fd41-e15a5e2d5fe8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "0    93\n",
       "6    79\n",
       "4    68\n",
       "5    46\n",
       "3    44\n",
       "1    44\n",
       "2    40\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "qJO4yFDY2nTP"
   },
   "outputs": [],
   "source": [
    "# train_data['enc_label'] = train_data['label'].replace({'non_damage':0,'damaged_infrastructure':1,'damaged_nature':2,\n",
    "#                                                        'fires':3,'flood':4,'human_damage':5 })\n",
    "# test_data['enc_label'] = test_data['label'].replace({'non_damage':0,'damaged_infrastructure':1,'damaged_nature':2,\n",
    "#                                                      'fires':3,'flood':4,'human_damage':5 })\n",
    "\n",
    "\n",
    "train_data['enc_label'] = train_data['Label_Sentiment'].replace({'happy':0,'angry':1,'disgust':2,'fear':3,'sad':4,'surprise':5,'other':6})\n",
    "valid_data['enc_label'] = valid_data['Label_Sentiment'].replace({'happy':0,'angry':1,'disgust':2,'fear':3,'sad':4,'surprise':5,'other':6})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "TKtfQsnn_aSt"
   },
   "outputs": [],
   "source": [
    "test_data['enc_label'] = test_data['Label_Sentiment'].replace({'happy':0,'angry':1,'disgust':2,'fear':3,'sad':4,'surprise':5,'other':6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NqXJL1QY3Gte",
    "outputId": "d3b8ffb6-8de6-4cc8-f523-a31463d8066e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the training data ==>  (3833, 5)\n",
      "Size of the training data ==>  (414, 5)\n",
      "Size of the Test data ==> (414, 5)\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of the training data ==> \", train_data.shape)\n",
    "print(\"Size of the training data ==> \", valid_data.shape)\n",
    "print(\"Size of the Test data ==>\", test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-f7tj6t_MbR2"
   },
   "source": [
    "## Image Fetching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ER4zNOmfMe_8"
   },
   "outputs": [],
   "source": [
    "## collect image names from the folders\n",
    "def create_img_array(img_dirct):\n",
    "    all_imgs = []\n",
    "    for root, j, files in os.walk(img_dirct):\n",
    "        for file in files:\n",
    "            file = root + '' + file\n",
    "            all_imgs.append(file)\n",
    "    return all_imgs\n",
    "\n",
    "def create_img_path(DF, Col_name, img_dir):\n",
    "    img_path = [img_dir + '' + name for name in DF[Col_name]]\n",
    "    return img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "1X--YjxFMo4v"
   },
   "outputs": [],
   "source": [
    "# Creating train, test and validation image path\n",
    "train_img_path = create_img_path(train_data,'image_name', dataset_path)\n",
    "valid_img_path = create_img_path(valid_data,'image_name', dataset_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "LI_xecOf_UD4"
   },
   "outputs": [],
   "source": [
    "test_img_path = create_img_path(test_data,'image_name', dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "t3FUNU_bM7Tn"
   },
   "outputs": [],
   "source": [
    "# Function that returns image reading from the path\n",
    "def get_input(path):\n",
    "    # Loading image from given path\n",
    "    # and resizing it to 150*150*3 format\n",
    "    ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "    img= tf.keras.utils.load_img(path, target_size=(150,150)) \n",
    "    # img.close()   \n",
    "    return(img)\n",
    "\n",
    "# Takes in image and preprocess it\n",
    "def process_input(img):\n",
    "    # Converting image to array    \n",
    "    img_data =tf.keras.utils.img_to_array(img)\n",
    "    # Adding one more dimension to array    \n",
    "    img_data = np.expand_dims(img_data, axis=0)\n",
    "    #     \n",
    "    img_data = preprocess_input(img_data)\n",
    "    #img_data = preprocess_input(img_data)\n",
    "    return(img_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "pUdvKi_yNCb5"
   },
   "outputs": [],
   "source": [
    "# Create an array of training images\n",
    "train_images = []\n",
    "for n,i in enumerate(train_img_path):\n",
    "  input_img = get_input(i)\n",
    "  process_img = process_input(input_img)\n",
    "  # print(n)\n",
    "  train_images.append(process_img[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "WPLJrKoAMXxE"
   },
   "outputs": [],
   "source": [
    "# Create an array of training images\n",
    "valid_images = []\n",
    "for n,i in enumerate(valid_img_path):\n",
    "  input_img = get_input(i)\n",
    "  process_img = process_input(input_img)\n",
    "  # print(n)\n",
    "  valid_images.append(process_img[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "KeGcMyaKY7s_"
   },
   "outputs": [],
   "source": [
    "# Create an array of training images\n",
    "test_images = []\n",
    "for n,i in enumerate(test_img_path):\n",
    "  input_img = get_input(i)\n",
    "  process_img = process_input(input_img)\n",
    "  # print(n)\n",
    "  test_images.append(process_img[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "PTGSeCyIb3i0"
   },
   "outputs": [],
   "source": [
    "# convert into numpy array\n",
    "train_image = np.array(train_images)\n",
    "# convert into numpy array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "fjUW4W8RMdS3"
   },
   "outputs": [],
   "source": [
    "valid_image = np.array(valid_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "R6dx_Cjb_lCv"
   },
   "outputs": [],
   "source": [
    "test_image = np.array(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "cT1sl0lZx_KG"
   },
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "with open(dataset_path+'train.pkl','wb') as f:\n",
    "    pkl.dump(train_image, f)\n",
    "\n",
    "# with open(dataset_path+'test.pkl','wb') as f:\n",
    "#     pkl.dump(test_image, f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "hVimkLOoMjW0"
   },
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "with open(dataset_path+'valid.pkl','wb') as f:\n",
    "    pkl.dump(valid_image, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "wk1ZnD8YAwIF"
   },
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "\n",
    "with open(dataset_path+'test.pkl','wb') as f:\n",
    "    pkl.dump(test_image, f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "AKDZjc1uxvvh",
    "outputId": "bfe99a81-34b8-40f4-a42d-55d15d12e6de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Images:--  (3833, 150, 150, 3)\n"
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "with open(dataset_path+'train.pkl','rb') as f:\n",
    "  train_image = pkl.load(f)\n",
    "  print(\"Training Images:-- \",train_image.shape)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "AlUS5zduMnG1",
    "outputId": "e425b343-484f-4df6-b4cf-9cc3248d2d1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Images:--  (414, 150, 150, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open(dataset_path+'valid.pkl','rb') as f:\n",
    "  valid_image = pkl.load(f)\n",
    "  print(\"Validation Images:-- \",valid_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "6kG8SrK5A1Dm",
    "outputId": "9621d0f1-7b0e-4288-807b-9a8e01551c1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Images:--  (414, 150, 150, 3)\n"
     ]
    }
   ],
   "source": [
    "with open(dataset_path+'test.pkl','rb') as f:\n",
    "  test_image = pkl.load(f)\n",
    "  print(\"Test Images:-- \",test_image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C55eRoK23rzC"
   },
   "source": [
    "## One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "dNGZabRk3vSN"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "vfd2Z0c-3x6_"
   },
   "outputs": [],
   "source": [
    "# encoder=OneHotEncoder(sparse=False)\n",
    "\n",
    "# encoded_labels = pd.DataFrame (encoder.fit_transform(train_data[['label']]))\n",
    "\n",
    "# encoded_labels .columns = encoder.get_feature_names(['label'])\n",
    "\n",
    "# train_data= pd.concat([train_data, encoded_labels ], axis=1)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Define the list of categories for your Label_Sentiment variable\n",
    "categories = ['happy', 'angry', 'disgust', 'fear', 'sad', 'surprise', 'other']\n",
    "\n",
    "# Perform one-hot encoding using get_dummies() function\n",
    "encoded_labels = pd.get_dummies(train_data['Label_Sentiment'], columns=categories, prefix='Label_Sentiment')\n",
    "\n",
    "# Concatenate the encoded labels with your original train_data DataFrame\n",
    "train_data = pd.concat([train_data, encoded_labels], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "OmdmEo9033SX",
    "outputId": "a1af89ee-b7be-4602-bcd4-8c612f6c8d84"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['image_name', 'Captions', 'Label_Sentiment', 'Label', 'enc_label',\n",
       "       'Label_Sentiment_angry', 'Label_Sentiment_disgust',\n",
       "       'Label_Sentiment_fear', 'Label_Sentiment_happy',\n",
       "       'Label_Sentiment_other', 'Label_Sentiment_sad',\n",
       "       'Label_Sentiment_surprise'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "alEhfx5H3-tX",
    "outputId": "c409502e-dc0d-4972-fd7b-8a0403e64856"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>Captions</th>\n",
       "      <th>Label_Sentiment</th>\n",
       "      <th>Label</th>\n",
       "      <th>enc_label</th>\n",
       "      <th>angry</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>happy</th>\n",
       "      <th>other</th>\n",
       "      <th>sad</th>\n",
       "      <th>surprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Screenshot 2023-04-20 at 3.34.16 PM.png</td>\n",
       "      <td>আমি সম্পূর্ণ অবাক হয়েছিলাম যখন আমি দেখি এটি ফ...</td>\n",
       "      <td>surprise</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>996.jpg</td>\n",
       "      <td>এখানে ভালবাসা অনুভব করুন! ভালবাসা দিবস</td>\n",
       "      <td>happy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>992.jpg</td>\n",
       "      <td>সত্যি কথা বলতে, সবকিছু আমাকে চিৎকার করতে চায়।</td>\n",
       "      <td>angry</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99123189_2622639137993646_7342319916193677312_...</td>\n",
       "      <td>আশ্চর্যজনকভাবে ছবিটার সাথে বর্তমান বিশ্ব পরিস্...</td>\n",
       "      <td>surprise</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>990.jpg</td>\n",
       "      <td>খুব যত্নশীল হট হট হট হট হট হট হট হট - আমরা আরও...</td>\n",
       "      <td>angry</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4138</th>\n",
       "      <td>10015063_288553201304626_62844069571247761_o.jpg</td>\n",
       "      <td>এখন আমার মনে হচ্ছে আমরা দূরে সরে যাচ্ছি...... ...</td>\n",
       "      <td>sad</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4139</th>\n",
       "      <td>1001.jpg</td>\n",
       "      <td>জো এর প্রথম প্রেম</td>\n",
       "      <td>happy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4140</th>\n",
       "      <td>1000.jpg</td>\n",
       "      <td>চিত্রগ্রহণের প্রথম দিন #পাওয়ারলেস ব্যাক ২০১১ ...</td>\n",
       "      <td>happy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4141</th>\n",
       "      <td>100.jpg</td>\n",
       "      <td>এটি আমার ভ্যালেন্টাইন এর ১ জন ভাগ্নের। আমি আনন...</td>\n",
       "      <td>happy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4142</th>\n",
       "      <td>10.jpg</td>\n",
       "      <td>পরম ব্যাঙ্গর থেকে দুটি গাড়ি অপমান করে কেবল সে...</td>\n",
       "      <td>disgust</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4143 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             image_name  \\\n",
       "0               Screenshot 2023-04-20 at 3.34.16 PM.png   \n",
       "1                                               996.jpg   \n",
       "2                                               992.jpg   \n",
       "3     99123189_2622639137993646_7342319916193677312_...   \n",
       "4                                               990.jpg   \n",
       "...                                                 ...   \n",
       "4138   10015063_288553201304626_62844069571247761_o.jpg   \n",
       "4139                                           1001.jpg   \n",
       "4140                                           1000.jpg   \n",
       "4141                                            100.jpg   \n",
       "4142                                             10.jpg   \n",
       "\n",
       "                                               Captions Label_Sentiment  \\\n",
       "0     আমি সম্পূর্ণ অবাক হয়েছিলাম যখন আমি দেখি এটি ফ...        surprise   \n",
       "1                এখানে ভালবাসা অনুভব করুন! ভালবাসা দিবস           happy   \n",
       "2        সত্যি কথা বলতে, সবকিছু আমাকে চিৎকার করতে চায়।           angry   \n",
       "3     আশ্চর্যজনকভাবে ছবিটার সাথে বর্তমান বিশ্ব পরিস্...        surprise   \n",
       "4     খুব যত্নশীল হট হট হট হট হট হট হট হট - আমরা আরও...           angry   \n",
       "...                                                 ...             ...   \n",
       "4138  এখন আমার মনে হচ্ছে আমরা দূরে সরে যাচ্ছি...... ...             sad   \n",
       "4139                                  জো এর প্রথম প্রেম           happy   \n",
       "4140  চিত্রগ্রহণের প্রথম দিন #পাওয়ারলেস ব্যাক ২০১১ ...           happy   \n",
       "4141  এটি আমার ভ্যালেন্টাইন এর ১ জন ভাগ্নের। আমি আনন...           happy   \n",
       "4142  পরম ব্যাঙ্গর থেকে দুটি গাড়ি অপমান করে কেবল সে...         disgust   \n",
       "\n",
       "      Label  enc_label  angry  disgust   fear  happy  other    sad  surprise  \n",
       "0         5          5  False    False  False  False  False  False      True  \n",
       "1         0          0  False    False  False   True  False  False     False  \n",
       "2         1          1   True    False  False  False  False  False     False  \n",
       "3         5          5  False    False  False  False  False  False      True  \n",
       "4         1          1   True    False  False  False  False  False     False  \n",
       "...     ...        ...    ...      ...    ...    ...    ...    ...       ...  \n",
       "4138      4          4  False    False  False  False  False   True     False  \n",
       "4139      0          0  False    False  False   True  False  False     False  \n",
       "4140      0          0  False    False  False   True  False  False     False  \n",
       "4141      0          0  False    False  False   True  False  False     False  \n",
       "4142      2          2  False     True  False  False  False  False     False  \n",
       "\n",
       "[4143 rows x 12 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_data = train_data.rename(columns={'label_damaged_infrastructure':'damaged_infrastructure', 'label_damaged_nature':'damaged_nature', \n",
    "#                                         'label_fires':'fires','label_flood':'flood',\n",
    "#                                         'label_human_damage':'human_damage', 'label_non_damage':'non_damage'})\n",
    "\n",
    "\n",
    "train_data = train_data.rename(columns={'Label_Sentiment_happy':'happy', \n",
    "                                        'Label_Sentiment_angry':'angry',\n",
    "                                        'Label_Sentiment_disgust':'disgust',\n",
    "                                        'Label_Sentiment_fear':'fear',\n",
    "                                        'Label_Sentiment_sad':'sad',\n",
    "                                        'Label_Sentiment_surprise':'surprise',\n",
    "                                        'Label_Sentiment_other':'other'})\n",
    "     \n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "6-XCXOsb-zxc",
    "outputId": "35994343-9a9c-4298-e361-a89c8c7013e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['image_name', 'Captions', 'Label_Sentiment', 'Label', 'enc_label',\n",
       "       'angry', 'disgust', 'fear', 'happy', 'other', 'sad', 'surprise'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "48JRGZ4U6Kvv"
   },
   "outputs": [],
   "source": [
    "train_data.Captions = train_data.Captions.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gyyw4VqlFXS_"
   },
   "source": [
    "##Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "1rgUkMnlFbBU"
   },
   "outputs": [],
   "source": [
    "'''Evaluation Parameters'''\n",
    "\n",
    "def print_metrices(true,pred):\n",
    "    print(confusion_matrix(true,pred))\n",
    "    print(classification_report(true,pred))\n",
    "    print(\"Accuracy : \",accuracy_score(true,pred))\n",
    "    print(\"Precison : \",precision_score(true,pred, average = 'weighted'))\n",
    "    print(\"Recall : \",recall_score(true,pred,  average = 'weighted'))\n",
    "    print(\"F1 : \",f1_score(true,pred,  average = 'weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i27YJBb9V_jk"
   },
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "PwSSTl3kWB5T"
   },
   "outputs": [],
   "source": [
    "## Confusion matrix function\n",
    "def con_mat(true,pred,class_names,model_name):\n",
    "  cm = confusion_matrix(true,pred)\n",
    "  #sns.set()\n",
    "  plt.figure(figsize =(4, 3))\n",
    "  ax = plt.subplot()\n",
    " # 'Greys', 'Purples', 'Blues', 'Greens', 'Oranges', 'Reds','YlOrBr', 'YlOrRd', 'OrRd', 'PuRd', 'RdPu', 'BuPu',\n",
    "            #'GnBu', 'PuBu', 'YlGnBu', 'PuBuGn', 'BuGn', 'YlGn'\n",
    "  sns.heatmap(cm, annot=True,fmt=\"d\",cmap='YlOrRd', ax = ax,annot_kws={\"size\": 10},) #annot=True to annotate cells\n",
    "  # labels, title and ticks\n",
    "  ax.set_xlabel('Predicted labels',fontsize=10)\n",
    "  ax.set_ylabel('True labels',fontsize=10) \n",
    "  #ax.set_title(f'Confusion Matrix of {model_name}',fontsize=10) \n",
    "  ax.xaxis.set_ticklabels(class_names, rotation=45); ax.yaxis.set_ticklabels(class_names, rotation=45);\n",
    "  ax.xaxis.tick_top()\n",
    " # plt.savefig(folder_path + f\"{model_name}.png\",bbox_inches='tight',dpi =500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "3V-biqwYkfZm",
    "outputId": "30f434a7-42d0-495a-b911-1542aa4e50d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.6377770935960592,\n",
       " 1: 1.1360021935837674,\n",
       " 2: 1.5867483722711604,\n",
       " 3: 1.3796203796203796,\n",
       " 4: 0.8900107411385607,\n",
       " 5: 1.3270339525944908,\n",
       " 6: 0.7578196451435888}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import compute_class_weight\n",
    "class_weights = compute_class_weight(\n",
    "                                        class_weight = \"balanced\",\n",
    "                                        classes = np.unique(train_data['enc_label']),\n",
    "                                        y = train_data['enc_label']                                                   \n",
    "                                    )\n",
    "class_weights = dict(zip(np.unique(train_data['enc_label']), class_weights))\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pDf4t5nANV1N"
   },
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "3UdewIycNmIf"
   },
   "outputs": [],
   "source": [
    "''' Callbacks'''\n",
    "keras.backend.clear_session()\n",
    "def callbacks_check(model_name):\n",
    "  num_classes = 7\n",
    "  accuracy_threshold = 0.99\n",
    "\n",
    "  class myCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('accuracy')>accuracy_threshold):\n",
    "          print(\"\\nReached %2.2f%% accuracy so we will stop trianing\" % (accuracy_threshold*100))\n",
    "          self.model.stop_training = True\n",
    "\n",
    "  acc_callback = myCallback()\n",
    "  # Saved the Best Model\n",
    "  filepath = models_path+'Models_3/'+f\"{model_name}.h5\"\n",
    "  checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=2, save_best_only=True, \n",
    "                                             save_weights_only=False, mode='max')\n",
    "  # callback list\n",
    "  callback_list = [acc_callback, checkpoint] \n",
    "\n",
    "  return callback_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "yzaDrX3dlrjH"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train=to_categorical(train_data['enc_label'])\n",
    "y_valid=to_categorical(valid_data['enc_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "TMCC_pqPBAMr"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y_test=to_categorical(test_data['enc_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "VxoNP4ytlwJg",
    "outputId": "d28af7cf-1dd7-4d70-9450-987f1df501e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 1., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fE_uBG0a_Vej"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JSLsF0v4cZ7d"
   },
   "source": [
    "#Visual Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "XgScRY7xtyFD"
   },
   "outputs": [],
   "source": [
    "from keras.applications.densenet import DenseNet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "gsRonbngccEl"
   },
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "def visual_models():\n",
    "\n",
    "  # create the base pre-trained model\n",
    "  vgg = VGG16(weights='imagenet', include_top=False,input_shape=(150, 150, 3))\n",
    "  for layer in vgg.layers:\n",
    "      layer.trainable = False\n",
    "  # add a global spatial average pooling layer\n",
    "  x = vgg.output\n",
    "  pool = GlobalAveragePooling2D()(x)\n",
    "  \n",
    "  # image_flat = Flatten()(x)\n",
    "  # image_dense = Dense(128, activation='relu')(image_flat)\n",
    "  # image_drop = Dropout(0.2)(x)\n",
    "  # let's add a fully-connected layer\n",
    "  #flat = Flatten()(pool)\n",
    "  # and a logistic layer -- let's say we have 200 classes\n",
    "  #hidden1 = Dense(512, activation='relu')(flat)\n",
    "  #dropout = Dropout(0.1)(hidden1)\n",
    "  output = Dense(7, activation='softmax')(pool)\n",
    "  # this is the model we will train\n",
    "  vgg_img_model = Model(inputs=vgg.input, outputs=output)\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "  ##inception\n",
    "  inception = keras.applications.InceptionV3(weights='imagenet', include_top=False,input_shape=(150, 150, 3))\n",
    "  for layer in inception.layers:\n",
    "      layer.trainable = False\n",
    "  # add a global spatial average pooling layer\n",
    "  z = inception.output\n",
    "  pool2 = GlobalAveragePooling2D()(z)\n",
    "  output2 = Dense(7, activation='softmax')(pool2)\n",
    "  # this is the model we will train\n",
    "  inception_img_model = Model(inputs=inception.input, outputs=output2)\n",
    "\n",
    "\n",
    "\n",
    " \n",
    " \n",
    "\n",
    "  models = [vgg_img_model,inception_img_model]\n",
    "\n",
    "  return models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "EJv91NwYMse0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: vgg16\n",
      "\n",
      "Epoch 1/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 5.8832 - accuracy: 0.1661\n",
      "Epoch 1: val_accuracy improved from -inf to 0.20482, saving model to /Users/zaima/Desktop/Dataset/Multimodal Sentiment/Models_3/vgg16.h5\n",
      "130/130 [==============================] - 72s 526ms/step - loss: 5.8832 - accuracy: 0.1661 - val_loss: 4.5847 - val_accuracy: 0.2048\n",
      "Epoch 2/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 3.9774 - accuracy: 0.2155\n",
      "Epoch 2: val_accuracy improved from 0.20482 to 0.20964, saving model to /Users/zaima/Desktop/Dataset/Multimodal Sentiment/Models_3/vgg16.h5\n",
      "130/130 [==============================] - 66s 506ms/step - loss: 3.9774 - accuracy: 0.2155 - val_loss: 3.7069 - val_accuracy: 0.2096\n",
      "Epoch 3/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 3.1507 - accuracy: 0.2534\n",
      "Epoch 3: val_accuracy improved from 0.20964 to 0.26265, saving model to /Users/zaima/Desktop/Dataset/Multimodal Sentiment/Models_3/vgg16.h5\n",
      "130/130 [==============================] - 75s 579ms/step - loss: 3.1507 - accuracy: 0.2534 - val_loss: 2.7912 - val_accuracy: 0.2627\n",
      "Epoch 4/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 2.6642 - accuracy: 0.2701\n",
      "Epoch 4: val_accuracy improved from 0.26265 to 0.27470, saving model to /Users/zaima/Desktop/Dataset/Multimodal Sentiment/Models_3/vgg16.h5\n",
      "130/130 [==============================] - 93s 719ms/step - loss: 2.6642 - accuracy: 0.2701 - val_loss: 2.5048 - val_accuracy: 0.2747\n",
      "Epoch 5/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 2.3314 - accuracy: 0.3119\n",
      "Epoch 5: val_accuracy improved from 0.27470 to 0.32289, saving model to /Users/zaima/Desktop/Dataset/Multimodal Sentiment/Models_3/vgg16.h5\n",
      "130/130 [==============================] - 93s 717ms/step - loss: 2.3314 - accuracy: 0.3119 - val_loss: 2.1304 - val_accuracy: 0.3229\n",
      "Epoch 6/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 2.1310 - accuracy: 0.3210\n",
      "Epoch 6: val_accuracy did not improve from 0.32289\n",
      "130/130 [==============================] - 91s 700ms/step - loss: 2.1310 - accuracy: 0.3210 - val_loss: 2.1241 - val_accuracy: 0.3108\n",
      "Epoch 7/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 1.9772 - accuracy: 0.3389\n",
      "Epoch 7: val_accuracy improved from 0.32289 to 0.36386, saving model to /Users/zaima/Desktop/Dataset/Multimodal Sentiment/Models_3/vgg16.h5\n",
      "130/130 [==============================] - 93s 720ms/step - loss: 1.9772 - accuracy: 0.3389 - val_loss: 1.8855 - val_accuracy: 0.3639\n",
      "Epoch 8/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 1.8797 - accuracy: 0.3551\n",
      "Epoch 8: val_accuracy did not improve from 0.36386\n",
      "130/130 [==============================] - 98s 757ms/step - loss: 1.8797 - accuracy: 0.3551 - val_loss: 1.8733 - val_accuracy: 0.3277\n",
      "Epoch 9/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 1.7965 - accuracy: 0.3625\n",
      "Epoch 9: val_accuracy did not improve from 0.36386\n",
      "130/130 [==============================] - 97s 747ms/step - loss: 1.7965 - accuracy: 0.3625 - val_loss: 1.9307 - val_accuracy: 0.3229\n",
      "Epoch 10/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 1.7360 - accuracy: 0.3799\n",
      "Epoch 10: val_accuracy improved from 0.36386 to 0.38072, saving model to /Users/zaima/Desktop/Dataset/Multimodal Sentiment/Models_3/vgg16.h5\n",
      "130/130 [==============================] - 101s 780ms/step - loss: 1.7360 - accuracy: 0.3799 - val_loss: 1.7622 - val_accuracy: 0.3807\n",
      "Epoch 11/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 1.6819 - accuracy: 0.3828\n",
      "Epoch 11: val_accuracy did not improve from 0.38072\n",
      "130/130 [==============================] - 98s 756ms/step - loss: 1.6819 - accuracy: 0.3828 - val_loss: 1.7322 - val_accuracy: 0.3735\n",
      "Epoch 12/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 1.6522 - accuracy: 0.3857\n",
      "Epoch 12: val_accuracy improved from 0.38072 to 0.39036, saving model to /Users/zaima/Desktop/Dataset/Multimodal Sentiment/Models_3/vgg16.h5\n",
      "130/130 [==============================] - 96s 737ms/step - loss: 1.6522 - accuracy: 0.3857 - val_loss: 1.6841 - val_accuracy: 0.3904\n",
      "Epoch 13/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 1.6572 - accuracy: 0.3869\n",
      "Epoch 13: val_accuracy improved from 0.39036 to 0.39277, saving model to /Users/zaima/Desktop/Dataset/Multimodal Sentiment/Models_3/vgg16.h5\n",
      "130/130 [==============================] - 103s 790ms/step - loss: 1.6572 - accuracy: 0.3869 - val_loss: 1.6508 - val_accuracy: 0.3928\n",
      "Epoch 14/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 1.6111 - accuracy: 0.3917\n",
      "Epoch 14: val_accuracy improved from 0.39277 to 0.41205, saving model to /Users/zaima/Desktop/Dataset/Multimodal Sentiment/Models_3/vgg16.h5\n",
      "130/130 [==============================] - 113s 872ms/step - loss: 1.6111 - accuracy: 0.3917 - val_loss: 1.5881 - val_accuracy: 0.4120\n",
      "Epoch 15/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 1.5953 - accuracy: 0.4016\n",
      "Epoch 15: val_accuracy did not improve from 0.41205\n",
      "130/130 [==============================] - 114s 877ms/step - loss: 1.5953 - accuracy: 0.4016 - val_loss: 1.7793 - val_accuracy: 0.3807\n",
      "Epoch 16/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 1.5921 - accuracy: 0.3968\n",
      "Epoch 16: val_accuracy did not improve from 0.41205\n",
      "130/130 [==============================] - 114s 876ms/step - loss: 1.5921 - accuracy: 0.3968 - val_loss: 1.7454 - val_accuracy: 0.3783\n",
      "Epoch 17/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 1.5566 - accuracy: 0.4152\n",
      "Epoch 17: val_accuracy did not improve from 0.41205\n",
      "130/130 [==============================] - 100s 770ms/step - loss: 1.5566 - accuracy: 0.4152 - val_loss: 1.6784 - val_accuracy: 0.4000\n",
      "Epoch 18/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 1.5662 - accuracy: 0.4038\n",
      "Epoch 18: val_accuracy did not improve from 0.41205\n",
      "130/130 [==============================] - 123s 952ms/step - loss: 1.5662 - accuracy: 0.4038 - val_loss: 1.7304 - val_accuracy: 0.3880\n",
      "Epoch 19/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 1.5621 - accuracy: 0.4077\n",
      "Epoch 19: val_accuracy did not improve from 0.41205\n",
      "130/130 [==============================] - 128s 986ms/step - loss: 1.5621 - accuracy: 0.4077 - val_loss: 1.5683 - val_accuracy: 0.3928\n",
      "Epoch 20/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 1.5503 - accuracy: 0.4082\n",
      "Epoch 20: val_accuracy did not improve from 0.41205\n",
      "130/130 [==============================] - 121s 928ms/step - loss: 1.5503 - accuracy: 0.4082 - val_loss: 1.6814 - val_accuracy: 0.3735\n",
      "Epoch 21/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 1.5612 - accuracy: 0.4149\n",
      "Epoch 21: val_accuracy improved from 0.41205 to 0.41687, saving model to /Users/zaima/Desktop/Dataset/Multimodal Sentiment/Models_3/vgg16.h5\n",
      "130/130 [==============================] - 123s 948ms/step - loss: 1.5612 - accuracy: 0.4149 - val_loss: 1.5343 - val_accuracy: 0.4169\n",
      "Epoch 22/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 1.5415 - accuracy: 0.4091\n",
      "Epoch 22: val_accuracy did not improve from 0.41687\n",
      "130/130 [==============================] - 127s 980ms/step - loss: 1.5415 - accuracy: 0.4091 - val_loss: 1.6233 - val_accuracy: 0.4024\n",
      "Epoch 23/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 1.5459 - accuracy: 0.4079\n",
      "Epoch 23: val_accuracy improved from 0.41687 to 0.45060, saving model to /Users/zaima/Desktop/Dataset/Multimodal Sentiment/Models_3/vgg16.h5\n",
      "130/130 [==============================] - 123s 950ms/step - loss: 1.5459 - accuracy: 0.4079 - val_loss: 1.5531 - val_accuracy: 0.4506\n",
      "Epoch 24/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 1.5489 - accuracy: 0.4166\n",
      "Epoch 24: val_accuracy did not improve from 0.45060\n",
      "130/130 [==============================] - 117s 904ms/step - loss: 1.5489 - accuracy: 0.4166 - val_loss: 1.5920 - val_accuracy: 0.4072\n",
      "Epoch 25/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 1.5351 - accuracy: 0.4154\n",
      "Epoch 25: val_accuracy did not improve from 0.45060\n",
      "130/130 [==============================] - 124s 954ms/step - loss: 1.5351 - accuracy: 0.4154 - val_loss: 1.6467 - val_accuracy: 0.4193\n",
      "Epoch 26/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 1.5562 - accuracy: 0.4115\n",
      "Epoch 26: val_accuracy did not improve from 0.45060\n",
      "130/130 [==============================] - 128s 983ms/step - loss: 1.5562 - accuracy: 0.4115 - val_loss: 1.5270 - val_accuracy: 0.4241\n",
      "Epoch 27/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 1.5250 - accuracy: 0.4229\n",
      "Epoch 27: val_accuracy did not improve from 0.45060\n",
      "130/130 [==============================] - 124s 955ms/step - loss: 1.5250 - accuracy: 0.4229 - val_loss: 1.6652 - val_accuracy: 0.3904\n",
      "Epoch 28/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 1.5423 - accuracy: 0.4118\n",
      "Epoch 28: val_accuracy did not improve from 0.45060\n",
      "130/130 [==============================] - 126s 969ms/step - loss: 1.5423 - accuracy: 0.4118 - val_loss: 1.5003 - val_accuracy: 0.4410\n",
      "Epoch 29/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 1.5298 - accuracy: 0.4202\n",
      "Epoch 29: val_accuracy did not improve from 0.45060\n",
      "130/130 [==============================] - 123s 949ms/step - loss: 1.5298 - accuracy: 0.4202 - val_loss: 1.5893 - val_accuracy: 0.3880\n",
      "Epoch 30/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 1.5465 - accuracy: 0.4108\n",
      "Epoch 30: val_accuracy did not improve from 0.45060\n",
      "130/130 [==============================] - 127s 981ms/step - loss: 1.5465 - accuracy: 0.4108 - val_loss: 1.6056 - val_accuracy: 0.3952\n",
      "Epoch 31/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 1.5293 - accuracy: 0.4224\n",
      "Epoch 31: val_accuracy did not improve from 0.45060\n",
      "130/130 [==============================] - 124s 952ms/step - loss: 1.5293 - accuracy: 0.4224 - val_loss: 1.4852 - val_accuracy: 0.4410\n",
      "Epoch 32/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 1.5201 - accuracy: 0.4258\n",
      "Epoch 32: val_accuracy did not improve from 0.45060\n",
      "130/130 [==============================] - 126s 973ms/step - loss: 1.5201 - accuracy: 0.4258 - val_loss: 1.5833 - val_accuracy: 0.3952\n",
      "Epoch 33/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 1.5671 - accuracy: 0.4060\n",
      "Epoch 33: val_accuracy did not improve from 0.45060\n",
      "130/130 [==============================] - 124s 952ms/step - loss: 1.5671 - accuracy: 0.4060 - val_loss: 1.4548 - val_accuracy: 0.4386\n",
      "Epoch 34/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 1.5207 - accuracy: 0.4161\n",
      "Epoch 34: val_accuracy did not improve from 0.45060\n",
      "130/130 [==============================] - 124s 957ms/step - loss: 1.5207 - accuracy: 0.4161 - val_loss: 1.5288 - val_accuracy: 0.4169\n",
      "Epoch 35/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 1.5409 - accuracy: 0.4202\n",
      "Epoch 35: val_accuracy did not improve from 0.45060\n",
      "130/130 [==============================] - 126s 969ms/step - loss: 1.5409 - accuracy: 0.4202 - val_loss: 1.6877 - val_accuracy: 0.3542\n",
      "Epoch 36/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 1.5191 - accuracy: 0.4246\n",
      "Epoch 36: val_accuracy did not improve from 0.45060\n",
      "130/130 [==============================] - 125s 963ms/step - loss: 1.5191 - accuracy: 0.4246 - val_loss: 1.5451 - val_accuracy: 0.4386\n",
      "Epoch 37/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 1.5317 - accuracy: 0.4164\n",
      "Epoch 37: val_accuracy did not improve from 0.45060\n",
      "130/130 [==============================] - 125s 960ms/step - loss: 1.5317 - accuracy: 0.4164 - val_loss: 1.4759 - val_accuracy: 0.4337\n",
      "Epoch 38/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 1.5277 - accuracy: 0.4176\n",
      "Epoch 38: val_accuracy did not improve from 0.45060\n",
      "130/130 [==============================] - 135s 1s/step - loss: 1.5277 - accuracy: 0.4176 - val_loss: 1.5803 - val_accuracy: 0.4241\n",
      "Epoch 39/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 1.5230 - accuracy: 0.4224\n",
      "Epoch 39: val_accuracy did not improve from 0.45060\n",
      "130/130 [==============================] - 128s 988ms/step - loss: 1.5230 - accuracy: 0.4224 - val_loss: 1.5410 - val_accuracy: 0.4265\n",
      "Epoch 40/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 1.5200 - accuracy: 0.4280\n",
      "Epoch 40: val_accuracy did not improve from 0.45060\n",
      "130/130 [==============================] - 122s 942ms/step - loss: 1.5200 - accuracy: 0.4280 - val_loss: 1.7942 - val_accuracy: 0.3687\n",
      "Epoch 41/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 1.5279 - accuracy: 0.4205\n",
      "Epoch 41: val_accuracy did not improve from 0.45060\n",
      "130/130 [==============================] - 125s 962ms/step - loss: 1.5279 - accuracy: 0.4205 - val_loss: 1.5770 - val_accuracy: 0.4000\n",
      "Epoch 42/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 1.5650 - accuracy: 0.4123\n",
      "Epoch 42: val_accuracy did not improve from 0.45060\n",
      "130/130 [==============================] - 124s 953ms/step - loss: 1.5650 - accuracy: 0.4123 - val_loss: 1.6681 - val_accuracy: 0.3711\n",
      "Epoch 43/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 1.5217 - accuracy: 0.4173\n",
      "Epoch 43: val_accuracy did not improve from 0.45060\n",
      "130/130 [==============================] - 123s 950ms/step - loss: 1.5217 - accuracy: 0.4173 - val_loss: 1.5903 - val_accuracy: 0.4096\n",
      "Epoch 44/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 1.5379 - accuracy: 0.4149\n",
      "Epoch 44: val_accuracy did not improve from 0.45060\n",
      "130/130 [==============================] - 122s 940ms/step - loss: 1.5379 - accuracy: 0.4149 - val_loss: 1.6284 - val_accuracy: 0.3759\n",
      "Epoch 45/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 1.5164 - accuracy: 0.4251\n",
      "Epoch 45: val_accuracy improved from 0.45060 to 0.46265, saving model to /Users/zaima/Desktop/Dataset/Multimodal Sentiment/Models_3/vgg16.h5\n",
      "130/130 [==============================] - 118s 906ms/step - loss: 1.5164 - accuracy: 0.4251 - val_loss: 1.4603 - val_accuracy: 0.4627\n",
      "Epoch 46/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 1.5405 - accuracy: 0.4224\n",
      "Epoch 46: val_accuracy did not improve from 0.46265\n",
      "130/130 [==============================] - 116s 891ms/step - loss: 1.5405 - accuracy: 0.4224 - val_loss: 1.5810 - val_accuracy: 0.4217\n",
      "Epoch 47/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 1.5302 - accuracy: 0.4251\n",
      "Epoch 47: val_accuracy did not improve from 0.46265\n",
      "130/130 [==============================] - 118s 911ms/step - loss: 1.5302 - accuracy: 0.4251 - val_loss: 1.6415 - val_accuracy: 0.4048\n",
      "Epoch 48/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 1.5640 - accuracy: 0.4127\n",
      "Epoch 48: val_accuracy did not improve from 0.46265\n",
      "130/130 [==============================] - 123s 945ms/step - loss: 1.5640 - accuracy: 0.4127 - val_loss: 1.6417 - val_accuracy: 0.4120\n",
      "Epoch 49/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 1.5297 - accuracy: 0.4226\n",
      "Epoch 49: val_accuracy did not improve from 0.46265\n",
      "130/130 [==============================] - 131s 1s/step - loss: 1.5297 - accuracy: 0.4226 - val_loss: 1.5729 - val_accuracy: 0.4048\n",
      "Epoch 50/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 1.5415 - accuracy: 0.4106\n",
      "Epoch 50: val_accuracy did not improve from 0.46265\n",
      "130/130 [==============================] - 122s 939ms/step - loss: 1.5415 - accuracy: 0.4106 - val_loss: 1.7067 - val_accuracy: 0.3663\n",
      "Epoch 51/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 1.5219 - accuracy: 0.4123\n",
      "Epoch 51: val_accuracy did not improve from 0.46265\n",
      "130/130 [==============================] - 121s 931ms/step - loss: 1.5219 - accuracy: 0.4123 - val_loss: 1.6156 - val_accuracy: 0.4000\n",
      "Model Name: inception\n",
      "\n",
      "Epoch 1/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 9.6758 - accuracy: 0.1535\n",
      "Epoch 1: val_accuracy improved from -inf to 0.16386, saving model to /Users/zaima/Desktop/Dataset/Multimodal Sentiment/Models_3/inception.h5\n",
      "130/130 [==============================] - 48s 282ms/step - loss: 9.6758 - accuracy: 0.1535 - val_loss: 6.8956 - val_accuracy: 0.1639\n",
      "Epoch 2/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 6.3291 - accuracy: 0.1863\n",
      "Epoch 2: val_accuracy did not improve from 0.16386\n",
      "130/130 [==============================] - 44s 343ms/step - loss: 6.3291 - accuracy: 0.1863 - val_loss: 5.9393 - val_accuracy: 0.1494\n",
      "Epoch 3/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 5.5315 - accuracy: 0.1984\n",
      "Epoch 3: val_accuracy improved from 0.16386 to 0.20723, saving model to /Users/zaima/Desktop/Dataset/Multimodal Sentiment/Models_3/inception.h5\n",
      "130/130 [==============================] - 42s 324ms/step - loss: 5.5315 - accuracy: 0.1984 - val_loss: 4.5007 - val_accuracy: 0.2072\n",
      "Epoch 4/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 5.1147 - accuracy: 0.2136\n",
      "Epoch 4: val_accuracy did not improve from 0.20723\n",
      "130/130 [==============================] - 40s 311ms/step - loss: 5.1147 - accuracy: 0.2136 - val_loss: 4.8583 - val_accuracy: 0.2048\n",
      "Epoch 5/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 4.8359 - accuracy: 0.2370\n",
      "Epoch 5: val_accuracy improved from 0.20723 to 0.22410, saving model to /Users/zaima/Desktop/Dataset/Multimodal Sentiment/Models_3/inception.h5\n",
      "130/130 [==============================] - 43s 332ms/step - loss: 4.8359 - accuracy: 0.2370 - val_loss: 4.7870 - val_accuracy: 0.2241\n",
      "Epoch 6/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 4.6532 - accuracy: 0.2315\n",
      "Epoch 6: val_accuracy improved from 0.22410 to 0.29157, saving model to /Users/zaima/Desktop/Dataset/Multimodal Sentiment/Models_3/inception.h5\n",
      "130/130 [==============================] - 42s 322ms/step - loss: 4.6532 - accuracy: 0.2315 - val_loss: 5.3086 - val_accuracy: 0.2916\n",
      "Epoch 7/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 3.9517 - accuracy: 0.2645\n",
      "Epoch 7: val_accuracy did not improve from 0.29157\n",
      "130/130 [==============================] - 41s 314ms/step - loss: 3.9517 - accuracy: 0.2645 - val_loss: 4.1629 - val_accuracy: 0.2386\n",
      "Epoch 8/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 3.4378 - accuracy: 0.2870\n",
      "Epoch 8: val_accuracy improved from 0.29157 to 0.32530, saving model to /Users/zaima/Desktop/Dataset/Multimodal Sentiment/Models_3/inception.h5\n",
      "130/130 [==============================] - 42s 321ms/step - loss: 3.4378 - accuracy: 0.2870 - val_loss: 3.4079 - val_accuracy: 0.3253\n",
      "Epoch 9/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 3.2314 - accuracy: 0.2867\n",
      "Epoch 9: val_accuracy improved from 0.32530 to 0.35181, saving model to /Users/zaima/Desktop/Dataset/Multimodal Sentiment/Models_3/inception.h5\n",
      "130/130 [==============================] - 40s 305ms/step - loss: 3.2314 - accuracy: 0.2867 - val_loss: 2.6513 - val_accuracy: 0.3518\n",
      "Epoch 10/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 3.2526 - accuracy: 0.2921\n",
      "Epoch 10: val_accuracy did not improve from 0.35181\n",
      "130/130 [==============================] - 37s 289ms/step - loss: 3.2526 - accuracy: 0.2921 - val_loss: 3.1078 - val_accuracy: 0.3253\n",
      "Epoch 11/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 3.4138 - accuracy: 0.2966\n",
      "Epoch 11: val_accuracy did not improve from 0.35181\n",
      "130/130 [==============================] - 39s 298ms/step - loss: 3.4138 - accuracy: 0.2966 - val_loss: 4.5991 - val_accuracy: 0.2386\n",
      "Epoch 12/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 3.6707 - accuracy: 0.3041\n",
      "Epoch 12: val_accuracy did not improve from 0.35181\n",
      "130/130 [==============================] - 40s 304ms/step - loss: 3.6707 - accuracy: 0.3041 - val_loss: 3.1370 - val_accuracy: 0.3157\n",
      "Epoch 13/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 3.3022 - accuracy: 0.3181\n",
      "Epoch 13: val_accuracy improved from 0.35181 to 0.41687, saving model to /Users/zaima/Desktop/Dataset/Multimodal Sentiment/Models_3/inception.h5\n",
      "130/130 [==============================] - 40s 306ms/step - loss: 3.3022 - accuracy: 0.3181 - val_loss: 2.1608 - val_accuracy: 0.4169\n",
      "Epoch 14/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 3.1898 - accuracy: 0.3208\n",
      "Epoch 14: val_accuracy did not improve from 0.41687\n",
      "130/130 [==============================] - 40s 309ms/step - loss: 3.1898 - accuracy: 0.3208 - val_loss: 2.9623 - val_accuracy: 0.3277\n",
      "Epoch 15/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 3.2501 - accuracy: 0.3338\n",
      "Epoch 15: val_accuracy did not improve from 0.41687\n",
      "130/130 [==============================] - 40s 305ms/step - loss: 3.2501 - accuracy: 0.3338 - val_loss: 5.2171 - val_accuracy: 0.1855\n",
      "Epoch 16/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 3.0948 - accuracy: 0.3287\n",
      "Epoch 16: val_accuracy did not improve from 0.41687\n",
      "130/130 [==============================] - 39s 301ms/step - loss: 3.0948 - accuracy: 0.3287 - val_loss: 2.4623 - val_accuracy: 0.3783\n",
      "Epoch 17/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 3.1382 - accuracy: 0.3345\n",
      "Epoch 17: val_accuracy improved from 0.41687 to 0.46024, saving model to /Users/zaima/Desktop/Dataset/Multimodal Sentiment/Models_3/inception.h5\n",
      "130/130 [==============================] - 40s 306ms/step - loss: 3.1382 - accuracy: 0.3345 - val_loss: 2.0802 - val_accuracy: 0.4602\n",
      "Epoch 18/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 3.1563 - accuracy: 0.3297\n",
      "Epoch 18: val_accuracy did not improve from 0.46024\n",
      "130/130 [==============================] - 40s 312ms/step - loss: 3.1563 - accuracy: 0.3297 - val_loss: 2.8992 - val_accuracy: 0.3422\n",
      "Epoch 19/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 2.7916 - accuracy: 0.3553\n",
      "Epoch 19: val_accuracy did not improve from 0.46024\n",
      "130/130 [==============================] - 42s 320ms/step - loss: 2.7916 - accuracy: 0.3553 - val_loss: 2.9300 - val_accuracy: 0.3663\n",
      "Epoch 20/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 2.5427 - accuracy: 0.3732\n",
      "Epoch 20: val_accuracy did not improve from 0.46024\n",
      "130/130 [==============================] - 41s 318ms/step - loss: 2.5427 - accuracy: 0.3732 - val_loss: 2.5701 - val_accuracy: 0.3687\n",
      "Epoch 21/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 2.9348 - accuracy: 0.3490\n",
      "Epoch 21: val_accuracy did not improve from 0.46024\n",
      "130/130 [==============================] - 40s 311ms/step - loss: 2.9348 - accuracy: 0.3490 - val_loss: 2.5041 - val_accuracy: 0.3711\n",
      "Epoch 22/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 2.9710 - accuracy: 0.3678\n",
      "Epoch 22: val_accuracy did not improve from 0.46024\n",
      "130/130 [==============================] - 40s 308ms/step - loss: 2.9710 - accuracy: 0.3678 - val_loss: 2.7144 - val_accuracy: 0.4337\n",
      "Epoch 23/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 2.5888 - accuracy: 0.3748\n",
      "Epoch 23: val_accuracy did not improve from 0.46024\n",
      "130/130 [==============================] - 38s 291ms/step - loss: 2.5888 - accuracy: 0.3748 - val_loss: 3.0563 - val_accuracy: 0.3566\n",
      "Epoch 24/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 2.4460 - accuracy: 0.3888\n",
      "Epoch 24: val_accuracy did not improve from 0.46024\n",
      "130/130 [==============================] - 39s 303ms/step - loss: 2.4460 - accuracy: 0.3888 - val_loss: 2.5179 - val_accuracy: 0.3542\n",
      "Epoch 25/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 2.7390 - accuracy: 0.3855\n",
      "Epoch 25: val_accuracy did not improve from 0.46024\n",
      "130/130 [==============================] - 41s 313ms/step - loss: 2.7390 - accuracy: 0.3855 - val_loss: 3.9503 - val_accuracy: 0.2747\n",
      "Epoch 26/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 2.7376 - accuracy: 0.3763\n",
      "Epoch 26: val_accuracy did not improve from 0.46024\n",
      "130/130 [==============================] - 40s 310ms/step - loss: 2.7376 - accuracy: 0.3763 - val_loss: 4.2847 - val_accuracy: 0.2940\n",
      "Epoch 27/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 2.5505 - accuracy: 0.3886\n",
      "Epoch 27: val_accuracy did not improve from 0.46024\n",
      "130/130 [==============================] - 40s 307ms/step - loss: 2.5505 - accuracy: 0.3886 - val_loss: 2.6683 - val_accuracy: 0.3759\n",
      "Epoch 28/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 2.5451 - accuracy: 0.3961\n",
      "Epoch 28: val_accuracy did not improve from 0.46024\n",
      "130/130 [==============================] - 39s 299ms/step - loss: 2.5451 - accuracy: 0.3961 - val_loss: 3.0310 - val_accuracy: 0.3253\n",
      "Epoch 29/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 2.1673 - accuracy: 0.4140\n",
      "Epoch 29: val_accuracy did not improve from 0.46024\n",
      "130/130 [==============================] - 39s 297ms/step - loss: 2.1673 - accuracy: 0.4140 - val_loss: 2.7550 - val_accuracy: 0.4217\n",
      "Epoch 30/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 3.0365 - accuracy: 0.3758\n",
      "Epoch 30: val_accuracy did not improve from 0.46024\n",
      "130/130 [==============================] - 40s 308ms/step - loss: 3.0365 - accuracy: 0.3758 - val_loss: 5.1085 - val_accuracy: 0.2554\n",
      "Epoch 31/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 2.4500 - accuracy: 0.4000\n",
      "Epoch 31: val_accuracy did not improve from 0.46024\n",
      "130/130 [==============================] - 38s 296ms/step - loss: 2.4500 - accuracy: 0.4000 - val_loss: 2.3668 - val_accuracy: 0.4337\n",
      "Epoch 32/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 2.3157 - accuracy: 0.4147\n",
      "Epoch 32: val_accuracy did not improve from 0.46024\n",
      "130/130 [==============================] - 40s 308ms/step - loss: 2.3157 - accuracy: 0.4147 - val_loss: 2.6969 - val_accuracy: 0.3928\n",
      "Epoch 33/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 2.4521 - accuracy: 0.3997\n",
      "Epoch 33: val_accuracy did not improve from 0.46024\n",
      "130/130 [==============================] - 40s 308ms/step - loss: 2.4521 - accuracy: 0.3997 - val_loss: 2.4465 - val_accuracy: 0.3880\n",
      "Epoch 34/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 2.2381 - accuracy: 0.4241\n",
      "Epoch 34: val_accuracy did not improve from 0.46024\n",
      "130/130 [==============================] - 40s 311ms/step - loss: 2.2381 - accuracy: 0.4241 - val_loss: 2.4853 - val_accuracy: 0.3976\n",
      "Epoch 35/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 2.6090 - accuracy: 0.3922\n",
      "Epoch 35: val_accuracy improved from 0.46024 to 0.46747, saving model to /Users/zaima/Desktop/Dataset/Multimodal Sentiment/Models_3/inception.h5\n",
      "130/130 [==============================] - 42s 320ms/step - loss: 2.6090 - accuracy: 0.3922 - val_loss: 1.9416 - val_accuracy: 0.4675\n",
      "Epoch 36/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 2.2869 - accuracy: 0.4294\n",
      "Epoch 36: val_accuracy did not improve from 0.46747\n",
      "130/130 [==============================] - 42s 326ms/step - loss: 2.2869 - accuracy: 0.4294 - val_loss: 2.4436 - val_accuracy: 0.4337\n",
      "Epoch 37/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 2.0899 - accuracy: 0.4337\n",
      "Epoch 37: val_accuracy did not improve from 0.46747\n",
      "130/130 [==============================] - 43s 331ms/step - loss: 2.0899 - accuracy: 0.4337 - val_loss: 2.6779 - val_accuracy: 0.3614\n",
      "Epoch 38/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 2.1903 - accuracy: 0.4424\n",
      "Epoch 38: val_accuracy did not improve from 0.46747\n",
      "130/130 [==============================] - 47s 362ms/step - loss: 2.1903 - accuracy: 0.4424 - val_loss: 2.7355 - val_accuracy: 0.3614\n",
      "Epoch 39/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 2.5138 - accuracy: 0.4123\n",
      "Epoch 39: val_accuracy did not improve from 0.46747\n",
      "130/130 [==============================] - 46s 354ms/step - loss: 2.5138 - accuracy: 0.4123 - val_loss: 2.5830 - val_accuracy: 0.4169\n",
      "Epoch 40/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 2.6319 - accuracy: 0.4135\n",
      "Epoch 40: val_accuracy did not improve from 0.46747\n",
      "130/130 [==============================] - 42s 320ms/step - loss: 2.6319 - accuracy: 0.4135 - val_loss: 3.0293 - val_accuracy: 0.4120\n",
      "Epoch 41/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 2.1986 - accuracy: 0.4359\n",
      "Epoch 41: val_accuracy did not improve from 0.46747\n",
      "130/130 [==============================] - 42s 324ms/step - loss: 2.1986 - accuracy: 0.4359 - val_loss: 2.2331 - val_accuracy: 0.4410\n",
      "Epoch 42/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 2.2154 - accuracy: 0.4299\n",
      "Epoch 42: val_accuracy did not improve from 0.46747\n",
      "130/130 [==============================] - 45s 343ms/step - loss: 2.2154 - accuracy: 0.4299 - val_loss: 2.6457 - val_accuracy: 0.4024\n",
      "Epoch 43/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 2.2381 - accuracy: 0.4388\n",
      "Epoch 43: val_accuracy did not improve from 0.46747\n",
      "130/130 [==============================] - 42s 326ms/step - loss: 2.2381 - accuracy: 0.4388 - val_loss: 2.4515 - val_accuracy: 0.4289\n",
      "Epoch 44/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 2.1677 - accuracy: 0.4352\n",
      "Epoch 44: val_accuracy improved from 0.46747 to 0.55904, saving model to /Users/zaima/Desktop/Dataset/Multimodal Sentiment/Models_3/inception.h5\n",
      "130/130 [==============================] - 41s 314ms/step - loss: 2.1677 - accuracy: 0.4352 - val_loss: 1.5732 - val_accuracy: 0.5590\n",
      "Epoch 45/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 2.4120 - accuracy: 0.4328\n",
      "Epoch 45: val_accuracy did not improve from 0.55904\n",
      "130/130 [==============================] - 41s 313ms/step - loss: 2.4120 - accuracy: 0.4328 - val_loss: 3.8240 - val_accuracy: 0.4265\n",
      "Epoch 46/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 2.2817 - accuracy: 0.4427\n",
      "Epoch 46: val_accuracy did not improve from 0.55904\n",
      "130/130 [==============================] - 42s 321ms/step - loss: 2.2817 - accuracy: 0.4427 - val_loss: 1.8268 - val_accuracy: 0.4771\n",
      "Epoch 47/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 2.0950 - accuracy: 0.4625\n",
      "Epoch 47: val_accuracy did not improve from 0.55904\n",
      "130/130 [==============================] - 42s 324ms/step - loss: 2.0950 - accuracy: 0.4625 - val_loss: 2.5307 - val_accuracy: 0.3880\n",
      "Epoch 48/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 2.3000 - accuracy: 0.4482\n",
      "Epoch 48: val_accuracy did not improve from 0.55904\n",
      "130/130 [==============================] - 41s 313ms/step - loss: 2.3000 - accuracy: 0.4482 - val_loss: 3.6105 - val_accuracy: 0.4241\n",
      "Epoch 49/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 2.6314 - accuracy: 0.4253\n",
      "Epoch 49: val_accuracy did not improve from 0.55904\n",
      "130/130 [==============================] - 43s 329ms/step - loss: 2.6314 - accuracy: 0.4253 - val_loss: 2.6112 - val_accuracy: 0.4000\n",
      "Epoch 50/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 2.3072 - accuracy: 0.4480\n",
      "Epoch 50: val_accuracy did not improve from 0.55904\n",
      "130/130 [==============================] - 44s 335ms/step - loss: 2.3072 - accuracy: 0.4480 - val_loss: 2.0195 - val_accuracy: 0.5157\n",
      "Epoch 51/51\n",
      "130/130 [==============================] - ETA: 0s - loss: 2.1854 - accuracy: 0.4424\n",
      "Epoch 51: val_accuracy improved from 0.55904 to 0.59036, saving model to /Users/zaima/Desktop/Dataset/Multimodal Sentiment/Models_3/inception.h5\n",
      "130/130 [==============================] - 47s 361ms/step - loss: 2.1854 - accuracy: 0.4424 - val_loss: 1.4380 - val_accuracy: 0.5904\n"
     ]
    }
   ],
   "source": [
    "model_name = ['vgg16','inception']\n",
    "list_model = visual_models()\n",
    "\n",
    "for mn,model in enumerate(list_model):\n",
    "  if model == 'vgg16':\n",
    "      opt = \"RMSprop\"\n",
    "  else:\n",
    "      opt = \"adam\" \n",
    "  model.compile(loss='categorical_crossentropy', \n",
    "                      optimizer=opt\n",
    ", \n",
    "                      metrics = [\"accuracy\"])\n",
    "  print(f\"Model Name: {model_name[mn]}\\n\")\n",
    "  # Training model\n",
    "  model.fit(x=train_image, \n",
    "              y=y_train,\n",
    "              epochs=51, \n",
    "              batch_size =32,\n",
    "              validation_data=(valid_image,y_valid),\n",
    "              verbose = 1,\n",
    "              class_weight = class_weights,\n",
    "              callbacks = callbacks_check(model_name[mn])\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U543x2hvaEI9"
   },
   "source": [
    "## Visual Models Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "WbQQnBNkaEJA"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "visual_models = ['vgg16','inception']\n",
    "visual_model_names = ['VGG16','Inception']\n",
    "\n",
    "def visual_models_accuracy(saved_model): \n",
    "  my_dict = {}\n",
    "  # Prediction \n",
    "  model = load_model(models_path+'Models_3/'+f\"{saved_model}.h5\")\n",
    "  y_pred = np.argmax(model.predict(test_image), axis=-1)\n",
    "\n",
    "  y_true = test_data['enc_label']\n",
    "\n",
    "  my_dict['Accuracy'] = accuracy_score(y_true, y_pred)*100\n",
    "  my_dict['Precision'] = precision_score(y_true, y_pred,average = 'weighted')*100\n",
    "  my_dict['Recall'] = recall_score(y_true, y_pred,average = 'weighted')*100 \n",
    "  my_dict['F1 Score'] = f1_score(y_true, y_pred,average = 'weighted')*100 \n",
    "  my_dict['MCC'] = matthews_corrcoef(y_true, y_pred)*100\n",
    "  \n",
    "  return my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "ifFG2vO9aEJB"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-11 20:01:22.599817: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 5s 409ms/step\n",
      "13/13 [==============================] - 3s 173ms/step\n"
     ]
    }
   ],
   "source": [
    "accuracy = {f'{visual_model_names[i]}':visual_models_accuracy(model) for i,model in enumerate(visual_models)}\n",
    "# Save the performance parameter into json file\n",
    "with open(models_path+'Results_3/'+'visual_models_performance.json', 'w') as f:\n",
    "    json.dump(accuracy, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "95y1nWfzhLeU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m=======  Visual Models Performance on Test Data  =============\n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>VGG16</th>\n",
       "      <td>70.44</td>\n",
       "      <td>71.75</td>\n",
       "      <td>68.44</td>\n",
       "      <td>70.06</td>\n",
       "      <td>63.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Inception</th>\n",
       "      <td>71.62</td>\n",
       "      <td>72.09</td>\n",
       "      <td>68.62</td>\n",
       "      <td>70.31</td>\n",
       "      <td>64.23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Accuracy  Precision  Recall  F1 Score    MCC\n",
       "VGG16         70.44      71.75   68.44     70.06  63.15\n",
       "Inception     71.62      72.09   68.62     70.31  64.23"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the json file\n",
    "metrics = json.load(open(models_path+'Results_3/'+'visual_models_performance.json'))\n",
    "acc_list = []\n",
    "pr_list = []\n",
    "re_list = []\n",
    "f1_list = []\n",
    "mcc_list = []\n",
    "for i in metrics.keys():\n",
    "  acc_list.append(round(metrics[i]['Accuracy'],2))\n",
    "  pr_list.append(round(metrics[i]['Precision'],2))\n",
    "  re_list.append(round(metrics[i]['Recall'],2))\n",
    "  f1_list.append(round(metrics[i]['F1 Score'],2))\n",
    "  mcc_list.append(round(metrics[i]['MCC'],2))\n",
    "\n",
    "print (color.BOLD+f\"=======  Visual Models Performance on Test Data  =============\\n\"+color.END)\n",
    "# Create a dataframe\n",
    "performance_matrix = pd.DataFrame({'Accuracy':acc_list,'Precision':pr_list,\n",
    "                                   'Recall':re_list,'F1 Score':f1_list,'MCC':mcc_list},\n",
    "                                  index =['VGG16','Inception'])\n",
    "performance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
